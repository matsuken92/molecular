{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "# import altair as alt\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# alt.renderers.enable('notebook')\n",
    "\n",
    "sys.path.append('..')\n",
    "from lib.line_notif import send_message\n",
    "from lib.utils import reduce_mem_usage, current_time, unpickle, to_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All function used in this kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# import altair as alt\n",
    "# from altair.vega import v3\n",
    "from IPython.display import HTML\n",
    "\n",
    "# # using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\n",
    "# def prepare_altair():\n",
    "#     \"\"\"\n",
    "#     Helper function to prepare altair for working.\n",
    "#     \"\"\"\n",
    "\n",
    "#     vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v3.SCHEMA_VERSION\n",
    "#     vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
    "#     vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
    "#     vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
    "#     noext = \"?noext\"\n",
    "    \n",
    "#     paths = {\n",
    "#         'vega': vega_url + noext,\n",
    "#         'vega-lib': vega_lib_url + noext,\n",
    "#         'vega-lite': vega_lite_url + noext,\n",
    "#         'vega-embed': vega_embed_url + noext\n",
    "#     }\n",
    "    \n",
    "#     workaround = f\"\"\"    requirejs.config({{\n",
    "#         baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
    "#         paths: {paths}\n",
    "#     }});\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return workaround\n",
    "    \n",
    "\n",
    "def add_autoincrement(render_func):\n",
    "    # Keep track of unique <div/> IDs\n",
    "    cache = {}\n",
    "    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
    "        if autoincrement:\n",
    "            if id in cache:\n",
    "                counter = 1 + cache[id]\n",
    "                cache[id] = counter\n",
    "            else:\n",
    "                cache[id] = 0\n",
    "            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
    "        else:\n",
    "            if id not in cache:\n",
    "                cache[id] = 0\n",
    "            actual_id = id\n",
    "        return render_func(chart, id=actual_id)\n",
    "    # Cache will stay outside and \n",
    "    return wrapped\n",
    "           \n",
    "\n",
    "# @add_autoincrement\n",
    "# def render(chart, id=\"vega-chart\"):\n",
    "#     \"\"\"\n",
    "#     Helper function to plot altair visualizations.\n",
    "#     \"\"\"\n",
    "#     chart_str = \"\"\"\n",
    "#     <div id=\"{id}\"></div><script>\n",
    "#     require([\"vega-embed\"], function(vg_embed) {{\n",
    "#         const spec = {chart};     \n",
    "#         vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
    "#         console.log(\"anything?\");\n",
    "#     }});\n",
    "#     console.log(\"really...anything?\");\n",
    "#     </script>\n",
    "#     \"\"\"\n",
    "#     return HTML(\n",
    "#         chart_str.format(\n",
    "#             id=id,\n",
    "#             chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "    \n",
    "\n",
    "@jit\n",
    "def fast_auc(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "\n",
    "\n",
    "def eval_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast auc eval function for lgb.\n",
    "    \"\"\"\n",
    "    return 'auc', fast_auc(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    \"\"\"\n",
    "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
    "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "    \"\"\"\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "    \n",
    "\n",
    "def train_model_regression(X, X_test, y, params, folds, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= folds.n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= folds.n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "    \n",
    "\n",
    "\n",
    "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns == None else columns\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
    "                        'catboost_metric_name': 'AUC',\n",
    "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "                    }\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros((len(X), len(set(y.values))))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros((len(X_test), oof.shape[1]))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid\n",
    "        scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid[:, 1]))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= folds.n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= folds.n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "\n",
    "# # setting up altair\n",
    "# workaround = prepare_altair()\n",
    "# HTML(\"\".join((\n",
    "#     \"<script>\",\n",
    "#     workaround,\n",
    "#     \"</script>\",\n",
    "# )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_atom_info(df, atom_idx):\n",
    "    df = pd.merge(df, structures, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    \n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                            'x': f'x_{atom_idx}',\n",
    "                            'y': f'y_{atom_idx}',\n",
    "                            'z': f'z_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "def angle_feat(df):\n",
    "    df_feat = pd.DataFrame({\"id\":df.id.values}, index=df.index.values)\n",
    "    for axis in [\"x\", \"y\", \"z\"]:\n",
    "        df_feat[f\"{axis}_diff\"] = df[f\"{axis}_0\"] - df[f\"{axis}_1\"]\n",
    "\n",
    "    df_feat[\"diff_norm\"] = (df_feat.x_diff**2 + df_feat.y_diff**2 + df_feat.z_diff**2)**0.5\n",
    "    df_feat[\"zero_norm\"] = (df.x_0**2 + df.y_0**2 + df.z_0**2)**0.5\n",
    "\n",
    "    for axis in [\"x\", \"y\", \"z\"]:\n",
    "        df_feat[f\"{axis}_diff\"] = df_feat[f\"{axis}_diff\"].values / df_feat[\"diff_norm\"].values\n",
    "        df_feat[f\"{axis}_0\"] = df[f\"{axis}_0\"].values / df_feat[\"zero_norm\"].values\n",
    "\n",
    "    df_feat[\"f004:angle\"] = df_feat.x_diff*df_feat.x_0 + df_feat.x_diff*df_feat.y_0 + df_feat.x_diff*df_feat.z_0\n",
    "    df_feat[\"f004:angle_abs\"] = np.abs(df_feat[\"f004:angle\"])\n",
    "    return df_feat[[\"id\", \"f004:angle\", \"f004:angle_abs\"]]\n",
    "\n",
    "\n",
    "def angle_feature_conv():\n",
    "    train_ = pd.read_csv('../input/train.csv')\n",
    "    test_ = pd.read_csv('../input/test.csv')\n",
    "    train_ = map_atom_info(train_, 0)\n",
    "    train_ = map_atom_info(train_, 1)\n",
    "\n",
    "    test_ = map_atom_info(test_, 0)\n",
    "    test_ = map_atom_info(test_, 1)\n",
    "    angle_df_train = angle_feat(train_)\n",
    "    angle_df_test  = angle_feat(test_)\n",
    "    return angle_df_train, angle_df_test\n",
    "\n",
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    \n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "good_columns = [\n",
    "'molecule_atom_index_0_dist_min',\n",
    "'molecule_atom_index_0_dist_max',\n",
    "'molecule_atom_index_1_dist_min',\n",
    "'molecule_atom_index_0_dist_mean',\n",
    "'molecule_atom_index_0_dist_std',\n",
    "'dist',\n",
    "'molecule_atom_index_1_dist_std',\n",
    "'molecule_atom_index_1_dist_max',\n",
    "'molecule_atom_index_1_dist_mean',\n",
    "'molecule_atom_index_0_dist_max_diff',\n",
    "'molecule_atom_index_0_dist_max_div',\n",
    "'molecule_atom_index_0_dist_std_diff',\n",
    "'molecule_atom_index_0_dist_std_div',\n",
    "'atom_0_couples_count',\n",
    "'molecule_atom_index_0_dist_min_div',\n",
    "'molecule_atom_index_1_dist_std_diff',\n",
    "'molecule_atom_index_0_dist_mean_div',\n",
    "'atom_1_couples_count',\n",
    "'molecule_atom_index_0_dist_mean_diff',\n",
    "'molecule_couples',\n",
    "'atom_index_1',\n",
    "'molecule_dist_mean',\n",
    "'molecule_atom_index_1_dist_max_diff',\n",
    "'molecule_atom_index_0_y_1_std',\n",
    "'molecule_atom_index_1_dist_mean_diff',\n",
    "'molecule_atom_index_1_dist_std_div',\n",
    "'molecule_atom_index_1_dist_mean_div',\n",
    "'molecule_atom_index_1_dist_min_diff',\n",
    "'molecule_atom_index_1_dist_min_div',\n",
    "'molecule_atom_index_1_dist_max_div',\n",
    "'molecule_atom_index_0_z_1_std',\n",
    "'y_0',\n",
    "'molecule_type_dist_std_diff',\n",
    "'molecule_atom_1_dist_min_diff',\n",
    "'molecule_atom_index_0_x_1_std',\n",
    "'molecule_dist_min',\n",
    "'molecule_atom_index_0_dist_min_diff',\n",
    "'molecule_atom_index_0_y_1_mean_diff',\n",
    "'molecule_type_dist_min',\n",
    "'molecule_atom_1_dist_min_div',\n",
    "'atom_index_0',\n",
    "'molecule_dist_max',\n",
    "'molecule_atom_1_dist_std_diff',\n",
    "'molecule_type_dist_max',\n",
    "'molecule_atom_index_0_y_1_max_diff',\n",
    "'molecule_type_0_dist_std_diff',\n",
    "'molecule_type_dist_mean_diff',\n",
    "'molecule_atom_1_dist_mean',\n",
    "'molecule_atom_index_0_y_1_mean_div',\n",
    "'molecule_type_dist_mean_div',\n",
    "'type', \"f004:angle\", \"f004:angle_abs\",\n",
    "\"f003:cos_0_1\", \"f003:cos_1\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mdipole_moments.csv.zip\u001b[0m                 \u001b[01;32mstructures.csv\u001b[0m*\r\n",
      "\u001b[01;31mmagnetic_shielding_tensors.csv.zip\u001b[0m     \u001b[01;31mstructures.csv.zip\u001b[0m\r\n",
      "\u001b[01;31mmulliken_charges.csv.zip\u001b[0m               \u001b[01;31mstructures.zip\u001b[0m\r\n",
      "\u001b[01;31mpotential_energy.csv.zip\u001b[0m               \u001b[01;32mtest.csv\u001b[0m*\r\n",
      "\u001b[01;32msample_submission.csv\u001b[0m*                 \u001b[01;31mtest.csv.zip\u001b[0m\r\n",
      "\u001b[01;31msample_submission.csv.zip\u001b[0m              \u001b[01;32mtrain.csv\u001b[0m*\r\n",
      "\u001b[01;32mscalar_coupling_contributions.csv\u001b[0m*     \u001b[01;31mtrain.csv.zip\u001b[0m\r\n",
      "\u001b[01;31mscalar_coupling_contributions.csv.zip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder = '../input'\n",
    "train = pd.read_csv(f'{file_folder}/train.csv')\n",
    "test = pd.read_csv(f'{file_folder}/test.csv')\n",
    "sub = pd.read_csv(f'{file_folder}/sample_submission.csv')\n",
    "structures = pd.read_csv(f'{file_folder}/structures.csv')\n",
    "scalar_coupling_contributions = pd.read_csv(f'{file_folder}/scalar_coupling_contributions.csv')\n",
    "\n",
    "train = pd.merge(train, scalar_coupling_contributions, how = 'left',\n",
    "                  left_on  = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'],\n",
    "                  right_on = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential_energy = pd.read_csv(f'{file_folder}/potential_energy.csv')\n",
    "# mulliken_charges = pd.read_csv(f'{file_folder}/mulliken_charges.csv')\n",
    "# magnetic_shielding_tensors = pd.read_csv(f'{file_folder}/magnetic_shielding_tensors.csv')\n",
    "# dipole_moments = pd.read_csv(f'{file_folder}/dipole_moments.csv')\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (20, 10))\n",
    "# for i, t in enumerate(train['type'].unique()):\n",
    "#     plt.subplot(2, 4, i + 1);\n",
    "#     plt.scatter(train.loc[train['type'] == t, 'fc'], train.loc[train['type'] == t, 'scalar_coupling_constant'], label=t);\n",
    "#     plt.title(f'fc vs target \\n for {t} type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "In the hidden cell below I generate features as in my kernel: https://www.kaggle.com/artgor/brute-force-feature-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 861.82 Mb (68.5% reduction)\n",
      "Mem. usage decreased to 430.10 Mb (68.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = map_atom_info(train, 0)\n",
    "train = map_atom_info(train, 1)\n",
    "\n",
    "test = map_atom_info(test, 0)\n",
    "test = map_atom_info(test, 1)\n",
    "\n",
    "train_p_0 = train[['x_0', 'y_0', 'z_0']].values\n",
    "train_p_1 = train[['x_1', 'y_1', 'z_1']].values\n",
    "test_p_0 = test[['x_0', 'y_0', 'z_0']].values\n",
    "test_p_1 = test[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "train['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\n",
    "test['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)\n",
    "train['dist_x'] = (train['x_0'] - train['x_1']) ** 2\n",
    "test['dist_x'] = (test['x_0'] - test['x_1']) ** 2\n",
    "train['dist_y'] = (train['y_0'] - train['y_1']) ** 2\n",
    "test['dist_y'] = (test['y_0'] - test['y_1']) ** 2\n",
    "train['dist_z'] = (train['z_0'] - train['z_1']) ** 2\n",
    "test['dist_z'] = (test['z_0'] - test['z_1']) ** 2\n",
    "\n",
    "train['type_0'] = train['type'].apply(lambda x: x[0])\n",
    "test['type_0'] = test['type'].apply(lambda x: x[0])\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "angle_df_train, angle_df_test = angle_feature_conv()\n",
    "train = train.merge(angle_df_train, on=\"id\", how=\"left\")\n",
    "test = test.merge(angle_df_test, on=\"id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cos = unpickle(\"../processed/v001/train_003.df.pkl\", )[[\"id\", \"f003:cos_0_1\", \"f003:cos_1\"]]\n",
    "test_cos = unpickle(\"../processed/v001/test_003.df.pkl\", )[[\"id\", \"f003:cos_0_1\", \"f003:cos_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4658147, 78), (2505542, 73))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4658147, 3), (2505542, 3))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cos.shape, test_cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f003:cos_0_1</th>\n",
       "      <th>f003:cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>-0.333335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.333287</td>\n",
       "      <td>0.816482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.333335</td>\n",
       "      <td>0.816496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.333347</td>\n",
       "      <td>0.816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.333352</td>\n",
       "      <td>-0.333352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  f003:cos_0_1  f003:cos_1\n",
       "0   0      0.333335   -0.333335\n",
       "1   1     -0.333287    0.816482\n",
       "2   2     -0.333335    0.816496\n",
       "3   3     -0.333347    0.816500\n",
       "4   4      0.333352   -0.333352"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f003:cos_0_1</th>\n",
       "      <th>f003:cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  f003:cos_0_1  f003:cos_1\n",
       "0  4658147           1.0        -1.0\n",
       "1  4658148          -1.0         1.0\n",
       "2  4658149          -1.0         1.0\n",
       "3  4658150          -1.0         1.0\n",
       "4  4658151           1.0        -1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_cos, on=\"id\", how=\"left\")\n",
    "test = test.merge(test_cos, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 866.26 Mb (8.9% reduction)\n",
      "Mem. usage decreased to 432.49 Mb (9.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)\n",
    "\n",
    "for f in ['atom_1', 'type_0', 'type']:\n",
    "    if f in good_columns:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>fc</th>\n",
       "      <th>sd</th>\n",
       "      <th>pso</th>\n",
       "      <th>dso</th>\n",
       "      <th>...</th>\n",
       "      <th>molecule_type_dist_mean_diff</th>\n",
       "      <th>molecule_type_dist_mean_div</th>\n",
       "      <th>molecule_type_dist_max</th>\n",
       "      <th>molecule_type_dist_min</th>\n",
       "      <th>molecule_type_dist_std</th>\n",
       "      <th>molecule_type_dist_std_diff</th>\n",
       "      <th>f004:angle</th>\n",
       "      <th>f004:angle_abs</th>\n",
       "      <th>f003:cos_0_1</th>\n",
       "      <th>f003:cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.812500</td>\n",
       "      <td>83.00000</td>\n",
       "      <td>0.254639</td>\n",
       "      <td>1.258789</td>\n",
       "      <td>0.271973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091797</td>\n",
       "      <td>-0.003864</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>-0.333252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.257812</td>\n",
       "      <td>-11.03125</td>\n",
       "      <td>0.353027</td>\n",
       "      <td>2.857422</td>\n",
       "      <td>-3.433594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783203</td>\n",
       "      <td>0.160889</td>\n",
       "      <td>0.160889</td>\n",
       "      <td>-0.333252</td>\n",
       "      <td>0.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.257812</td>\n",
       "      <td>-11.03125</td>\n",
       "      <td>0.353027</td>\n",
       "      <td>2.859375</td>\n",
       "      <td>-3.433594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783203</td>\n",
       "      <td>-0.086548</td>\n",
       "      <td>0.086548</td>\n",
       "      <td>-0.333252</td>\n",
       "      <td>0.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.257812</td>\n",
       "      <td>-11.03125</td>\n",
       "      <td>0.353027</td>\n",
       "      <td>2.859375</td>\n",
       "      <td>-3.433594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783203</td>\n",
       "      <td>-0.083862</td>\n",
       "      <td>0.083862</td>\n",
       "      <td>-0.333252</td>\n",
       "      <td>0.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.812500</td>\n",
       "      <td>83.00000</td>\n",
       "      <td>0.254639</td>\n",
       "      <td>1.258789</td>\n",
       "      <td>0.271973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091797</td>\n",
       "      <td>1.305664</td>\n",
       "      <td>1.305664</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>-0.333252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0     0   \n",
       "1   1  dsgdb9nsd_000001             1             2     3   \n",
       "2   2  dsgdb9nsd_000001             1             3     3   \n",
       "3   3  dsgdb9nsd_000001             1             4     3   \n",
       "4   4  dsgdb9nsd_000001             2             0     0   \n",
       "\n",
       "   scalar_coupling_constant        fc        sd       pso       dso  \\\n",
       "0                 84.812500  83.00000  0.254639  1.258789  0.271973   \n",
       "1                -11.257812 -11.03125  0.353027  2.857422 -3.433594   \n",
       "2                -11.257812 -11.03125  0.353027  2.859375 -3.433594   \n",
       "3                -11.257812 -11.03125  0.353027  2.859375 -3.433594   \n",
       "4                 84.812500  83.00000  0.254639  1.258789  0.271973   \n",
       "\n",
       "      ...     molecule_type_dist_mean_diff  molecule_type_dist_mean_div  \\\n",
       "0     ...                        -0.000003                          1.0   \n",
       "1     ...                         0.000027                          1.0   \n",
       "2     ...                        -0.000001                          1.0   \n",
       "3     ...                        -0.000010                          1.0   \n",
       "4     ...                        -0.000002                          1.0   \n",
       "\n",
       "   molecule_type_dist_max  molecule_type_dist_min molecule_type_dist_std  \\\n",
       "0                1.091797                1.091797               0.000003   \n",
       "1                1.783203                1.783203               0.000014   \n",
       "2                1.783203                1.783203               0.000014   \n",
       "3                1.783203                1.783203               0.000014   \n",
       "4                1.091797                1.091797               0.000003   \n",
       "\n",
       "   molecule_type_dist_std_diff  f004:angle  f004:angle_abs  f003:cos_0_1  \\\n",
       "0                    -1.091797   -0.003864        0.003864      0.333252   \n",
       "1                    -1.783203    0.160889        0.160889     -0.333252   \n",
       "2                    -1.783203   -0.086548        0.086548     -0.333252   \n",
       "3                    -1.783203   -0.083862        0.083862     -0.333252   \n",
       "4                    -1.091797    1.305664        1.305664      0.333252   \n",
       "\n",
       "   f003:cos_1  \n",
       "0   -0.333252  \n",
       "1    0.816406  \n",
       "2    0.816406  \n",
       "3    0.816406  \n",
       "4   -0.333252  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>...</th>\n",
       "      <th>molecule_type_dist_mean_diff</th>\n",
       "      <th>molecule_type_dist_mean_div</th>\n",
       "      <th>molecule_type_dist_max</th>\n",
       "      <th>molecule_type_dist_min</th>\n",
       "      <th>molecule_type_dist_std</th>\n",
       "      <th>molecule_type_dist_std_diff</th>\n",
       "      <th>f004:angle</th>\n",
       "      <th>f004:angle_abs</th>\n",
       "      <th>f003:cos_0_1</th>\n",
       "      <th>f003:cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.662109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.261719</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.662109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.662109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.324219</td>\n",
       "      <td>3.324219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.662109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1.662109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.261719</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     molecule_name  atom_index_0  atom_index_1  type atom_0  \\\n",
       "0  4658147  dsgdb9nsd_000004             2             0     2      H   \n",
       "1  4658148  dsgdb9nsd_000004             2             1     0      H   \n",
       "2  4658149  dsgdb9nsd_000004             2             3     6      H   \n",
       "3  4658150  dsgdb9nsd_000004             3             0     0      H   \n",
       "4  4658151  dsgdb9nsd_000004             3             1     2      H   \n",
       "\n",
       "        x_0  y_0  z_0 atom_1     ...      molecule_type_dist_mean_diff  \\\n",
       "0 -1.662109  0.0  1.0      C     ...                               0.0   \n",
       "1 -1.662109  0.0  1.0      C     ...                               0.0   \n",
       "2 -1.662109  0.0  1.0      H     ...                               0.0   \n",
       "3  1.662109  0.0  1.0      C     ...                               0.0   \n",
       "4  1.662109  0.0  1.0      C     ...                               0.0   \n",
       "\n",
       "   molecule_type_dist_mean_div  molecule_type_dist_max  \\\n",
       "0                          1.0                2.261719   \n",
       "1                          1.0                1.062500   \n",
       "2                          1.0                3.324219   \n",
       "3                          1.0                1.062500   \n",
       "4                          1.0                2.261719   \n",
       "\n",
       "   molecule_type_dist_min  molecule_type_dist_std  \\\n",
       "0                2.261719                     0.0   \n",
       "1                1.062500                     0.0   \n",
       "2                3.324219                     NaN   \n",
       "3                1.062500                     0.0   \n",
       "4                2.261719                     0.0   \n",
       "\n",
       "   molecule_type_dist_std_diff  f004:angle f004:angle_abs  f003:cos_0_1  \\\n",
       "0                    -2.261719    0.341064       0.341064           1.0   \n",
       "1                    -1.062500    0.341064       0.341064          -1.0   \n",
       "2                          NaN    0.341064       0.341064          -1.0   \n",
       "3                    -1.062500    1.372070       1.372070          -1.0   \n",
       "4                    -2.261719    1.372070       1.372070           1.0   \n",
       "\n",
       "   f003:cos_1  \n",
       "0        -1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4        -1.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mkdir ../processed/v003/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(\"../processed/v003/train_v003.pkl\", train)\n",
    "to_pickle(\"../processed/v003/test_v003.pkl\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[good_columns].copy()\n",
    "y = train['scalar_coupling_constant']\n",
    "y_fc = train['fc']\n",
    "X_test = test[good_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train, test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'num_leaves': 128,\n",
    "#           'min_child_samples': 79,\n",
    "#           'objective': 'regression',\n",
    "#           'max_depth': 9,\n",
    "#           'learning_rate': 0.2,\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"subsample_freq\": 1,\n",
    "#           \"subsample\": 0.9,\n",
    "#           \"bagging_seed\": 11,\n",
    "#           \"metric\": 'mae',\n",
    "#           \"verbosity\": -1,\n",
    "#           'reg_alpha': 0.1,\n",
    "#           'reg_lambda': 0.3,\n",
    "#           'colsample_bytree': 1.0\n",
    "#          }\n",
    "# result_dict_lgb = train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "#                                                       verbose=500, early_stopping_rounds=200, n_estimators=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create out of fold feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 128,\n",
    "          'min_child_samples': 79,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.2,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 1.0,\n",
    "          'num_threads' : -1,\n",
    "         }\n",
    "result_dict_lgb1 = train_model_regression(X=X, \n",
    "                                          X_test=X_test, \n",
    "                                          y=y_fc, \n",
    "                                          params=params, \n",
    "                                          folds=folds, \n",
    "                                          model_type='lgb', \n",
    "                                          eval_metric='group_mae', \n",
    "                                          plot_feature_importance=False,\n",
    "                                          verbose=500, \n",
    "                                          early_stopping_rounds=200, \n",
    "                                          n_estimators=5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['oof_fc'] = result_dict_lgb1['oof']\n",
    "X_test['oof_fc'] = result_dict_lgb1['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(\"../processed/v003/train_oof_fc.pkl\", X['oof_fc'])\n",
    "to_pickle(\"../processed/v003/test_oof_fc.pkl\", X_test['oof_fc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training separate models for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of type 0\n",
      "Fold 1 started at Sun Jun  9 14:08:18 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 1.3439\tvalid_1's l1: 1.56969\n",
      "[1000]\ttraining's l1: 1.1373\tvalid_1's l1: 1.5436\n",
      "[1500]\ttraining's l1: 0.972497\tvalid_1's l1: 1.52225\n",
      "[2000]\ttraining's l1: 0.840186\tvalid_1's l1: 1.50481\n",
      "[2500]\ttraining's l1: 0.731405\tvalid_1's l1: 1.49131\n",
      "[3000]\ttraining's l1: 0.639926\tvalid_1's l1: 1.48156\n",
      "[3500]\ttraining's l1: 0.563047\tvalid_1's l1: 1.47215\n",
      "[4000]\ttraining's l1: 0.497852\tvalid_1's l1: 1.4652\n",
      "[4500]\ttraining's l1: 0.442307\tvalid_1's l1: 1.45987\n",
      "[5000]\ttraining's l1: 0.393986\tvalid_1's l1: 1.45527\n",
      "[5500]\ttraining's l1: 0.351996\tvalid_1's l1: 1.45104\n",
      "[6000]\ttraining's l1: 0.315039\tvalid_1's l1: 1.44829\n",
      "[6500]\ttraining's l1: 0.282614\tvalid_1's l1: 1.44573\n",
      "[7000]\ttraining's l1: 0.254175\tvalid_1's l1: 1.44337\n",
      "[7500]\ttraining's l1: 0.228931\tvalid_1's l1: 1.44134\n",
      "[8000]\ttraining's l1: 0.206604\tvalid_1's l1: 1.43969\n",
      "[8500]\ttraining's l1: 0.186769\tvalid_1's l1: 1.43834\n",
      "[9000]\ttraining's l1: 0.169012\tvalid_1's l1: 1.43705\n",
      "[9500]\ttraining's l1: 0.153214\tvalid_1's l1: 1.43579\n",
      "[10000]\ttraining's l1: 0.138953\tvalid_1's l1: 1.43497\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.138953\tvalid_1's l1: 1.43497\n",
      "Fold 2 started at Sun Jun  9 14:13:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 1.34783\tvalid_1's l1: 1.56899\n",
      "[1000]\ttraining's l1: 1.13826\tvalid_1's l1: 1.54313\n",
      "[1500]\ttraining's l1: 0.973116\tvalid_1's l1: 1.52435\n",
      "[2000]\ttraining's l1: 0.839804\tvalid_1's l1: 1.50788\n",
      "[2500]\ttraining's l1: 0.730667\tvalid_1's l1: 1.4949\n",
      "[3000]\ttraining's l1: 0.639073\tvalid_1's l1: 1.48331\n",
      "[3500]\ttraining's l1: 0.561765\tvalid_1's l1: 1.47466\n",
      "[4000]\ttraining's l1: 0.496963\tvalid_1's l1: 1.46806\n",
      "[4500]\ttraining's l1: 0.441167\tvalid_1's l1: 1.46258\n",
      "[5000]\ttraining's l1: 0.392971\tvalid_1's l1: 1.45787\n",
      "[5500]\ttraining's l1: 0.350912\tvalid_1's l1: 1.4537\n",
      "[6000]\ttraining's l1: 0.314099\tvalid_1's l1: 1.45061\n",
      "[6500]\ttraining's l1: 0.281897\tvalid_1's l1: 1.44774\n",
      "[7000]\ttraining's l1: 0.253506\tvalid_1's l1: 1.44561\n",
      "[7500]\ttraining's l1: 0.228476\tvalid_1's l1: 1.44366\n",
      "[8000]\ttraining's l1: 0.206226\tvalid_1's l1: 1.44226\n",
      "[8500]\ttraining's l1: 0.186411\tvalid_1's l1: 1.44076\n",
      "[9000]\ttraining's l1: 0.168668\tvalid_1's l1: 1.43964\n",
      "[9500]\ttraining's l1: 0.152898\tvalid_1's l1: 1.4386\n",
      "[10000]\ttraining's l1: 0.138754\tvalid_1's l1: 1.43781\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.138754\tvalid_1's l1: 1.43781\n",
      "Fold 3 started at Sun Jun  9 14:19:06 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 1.33523\tvalid_1's l1: 1.57543\n",
      "[1000]\ttraining's l1: 1.13008\tvalid_1's l1: 1.55084\n",
      "[1500]\ttraining's l1: 0.966156\tvalid_1's l1: 1.52938\n",
      "[2000]\ttraining's l1: 0.833167\tvalid_1's l1: 1.51276\n",
      "[2500]\ttraining's l1: 0.724919\tvalid_1's l1: 1.49787\n",
      "[3000]\ttraining's l1: 0.634408\tvalid_1's l1: 1.48671\n",
      "[3500]\ttraining's l1: 0.558389\tvalid_1's l1: 1.47835\n",
      "[4000]\ttraining's l1: 0.493709\tvalid_1's l1: 1.47075\n",
      "[4500]\ttraining's l1: 0.438317\tvalid_1's l1: 1.46572\n",
      "[5000]\ttraining's l1: 0.390185\tvalid_1's l1: 1.46074\n",
      "[5500]\ttraining's l1: 0.348544\tvalid_1's l1: 1.45705\n",
      "[6000]\ttraining's l1: 0.312298\tvalid_1's l1: 1.45445\n",
      "[6500]\ttraining's l1: 0.280644\tvalid_1's l1: 1.45147\n",
      "[7000]\ttraining's l1: 0.252295\tvalid_1's l1: 1.44902\n",
      "[7500]\ttraining's l1: 0.227406\tvalid_1's l1: 1.44728\n",
      "[8000]\ttraining's l1: 0.205352\tvalid_1's l1: 1.44564\n",
      "[8500]\ttraining's l1: 0.185655\tvalid_1's l1: 1.44452\n",
      "[9000]\ttraining's l1: 0.167971\tvalid_1's l1: 1.44347\n",
      "[9500]\ttraining's l1: 0.152356\tvalid_1's l1: 1.44235\n",
      "[10000]\ttraining's l1: 0.138266\tvalid_1's l1: 1.44144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.138266\tvalid_1's l1: 1.44144\n",
      "Fold 4 started at Sun Jun  9 14:24:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 1.34405\tvalid_1's l1: 1.57463\n",
      "[1000]\ttraining's l1: 1.13906\tvalid_1's l1: 1.54912\n",
      "[1500]\ttraining's l1: 0.974332\tvalid_1's l1: 1.52754\n",
      "[2000]\ttraining's l1: 0.840944\tvalid_1's l1: 1.51142\n",
      "[2500]\ttraining's l1: 0.731382\tvalid_1's l1: 1.49721\n",
      "[3000]\ttraining's l1: 0.639957\tvalid_1's l1: 1.48553\n",
      "[3500]\ttraining's l1: 0.563021\tvalid_1's l1: 1.47715\n",
      "[4000]\ttraining's l1: 0.497378\tvalid_1's l1: 1.47018\n",
      "[4500]\ttraining's l1: 0.441891\tvalid_1's l1: 1.46431\n",
      "[5000]\ttraining's l1: 0.392983\tvalid_1's l1: 1.45937\n",
      "[5500]\ttraining's l1: 0.350791\tvalid_1's l1: 1.45553\n",
      "[6000]\ttraining's l1: 0.314382\tvalid_1's l1: 1.45266\n",
      "[6500]\ttraining's l1: 0.282156\tvalid_1's l1: 1.45017\n",
      "[7000]\ttraining's l1: 0.253716\tvalid_1's l1: 1.44762\n",
      "[7500]\ttraining's l1: 0.228517\tvalid_1's l1: 1.44585\n",
      "[8000]\ttraining's l1: 0.206365\tvalid_1's l1: 1.44436\n",
      "[8500]\ttraining's l1: 0.186544\tvalid_1's l1: 1.44311\n",
      "[9000]\ttraining's l1: 0.16875\tvalid_1's l1: 1.442\n",
      "[9500]\ttraining's l1: 0.152938\tvalid_1's l1: 1.44094\n",
      "[10000]\ttraining's l1: 0.138899\tvalid_1's l1: 1.44016\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.138899\tvalid_1's l1: 1.44016\n",
      "Fold 5 started at Sun Jun  9 14:30:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 1.3404\tvalid_1's l1: 1.57346\n",
      "[1000]\ttraining's l1: 1.13382\tvalid_1's l1: 1.54773\n",
      "[1500]\ttraining's l1: 0.969657\tvalid_1's l1: 1.52816\n",
      "[2000]\ttraining's l1: 0.837582\tvalid_1's l1: 1.51103\n",
      "[2500]\ttraining's l1: 0.728772\tvalid_1's l1: 1.49732\n",
      "[3000]\ttraining's l1: 0.637803\tvalid_1's l1: 1.48569\n",
      "[3500]\ttraining's l1: 0.56128\tvalid_1's l1: 1.47659\n",
      "[4000]\ttraining's l1: 0.495872\tvalid_1's l1: 1.46914\n",
      "[4500]\ttraining's l1: 0.440328\tvalid_1's l1: 1.46329\n",
      "[5000]\ttraining's l1: 0.391838\tvalid_1's l1: 1.45893\n",
      "[5500]\ttraining's l1: 0.350524\tvalid_1's l1: 1.4552\n",
      "[6000]\ttraining's l1: 0.314045\tvalid_1's l1: 1.45215\n",
      "[6500]\ttraining's l1: 0.282028\tvalid_1's l1: 1.44964\n",
      "[7000]\ttraining's l1: 0.253741\tvalid_1's l1: 1.44717\n",
      "[7500]\ttraining's l1: 0.22857\tvalid_1's l1: 1.44503\n",
      "[8000]\ttraining's l1: 0.206321\tvalid_1's l1: 1.44338\n",
      "[8500]\ttraining's l1: 0.186369\tvalid_1's l1: 1.44194\n",
      "[9000]\ttraining's l1: 0.168579\tvalid_1's l1: 1.44064\n",
      "[9500]\ttraining's l1: 0.152879\tvalid_1's l1: 1.43961\n",
      "[10000]\ttraining's l1: 0.138527\tvalid_1's l1: 1.43887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.138527\tvalid_1's l1: 1.43887\n",
      "CV mean score: 0.3637, std: 0.0015.\n",
      "Training of type 3\n",
      "Fold 1 started at Sun Jun  9 14:35:19 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.265277\tvalid_1's l1: 0.351694\n",
      "[1000]\ttraining's l1: 0.191613\tvalid_1's l1: 0.328247\n",
      "[1500]\ttraining's l1: 0.147581\tvalid_1's l1: 0.318357\n",
      "[2000]\ttraining's l1: 0.117255\tvalid_1's l1: 0.31304\n",
      "[2500]\ttraining's l1: 0.094884\tvalid_1's l1: 0.309855\n",
      "[3000]\ttraining's l1: 0.0777627\tvalid_1's l1: 0.307824\n",
      "[3500]\ttraining's l1: 0.0642895\tvalid_1's l1: 0.306627\n",
      "[4000]\ttraining's l1: 0.0534611\tvalid_1's l1: 0.305747\n",
      "[4500]\ttraining's l1: 0.0447359\tvalid_1's l1: 0.305117\n",
      "[5000]\ttraining's l1: 0.0377019\tvalid_1's l1: 0.304589\n",
      "[5500]\ttraining's l1: 0.0318185\tvalid_1's l1: 0.304213\n",
      "[6000]\ttraining's l1: 0.0269719\tvalid_1's l1: 0.303917\n",
      "[6500]\ttraining's l1: 0.0229437\tvalid_1's l1: 0.303757\n",
      "[7000]\ttraining's l1: 0.0195845\tvalid_1's l1: 0.303595\n",
      "[7500]\ttraining's l1: 0.0168002\tvalid_1's l1: 0.303449\n",
      "[8000]\ttraining's l1: 0.0144635\tvalid_1's l1: 0.303352\n",
      "[8500]\ttraining's l1: 0.0124916\tvalid_1's l1: 0.303261\n",
      "[9000]\ttraining's l1: 0.0108554\tvalid_1's l1: 0.303184\n",
      "[9500]\ttraining's l1: 0.00945344\tvalid_1's l1: 0.303113\n",
      "[10000]\ttraining's l1: 0.00828106\tvalid_1's l1: 0.303066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00828106\tvalid_1's l1: 0.303066\n",
      "Fold 2 started at Sun Jun  9 14:39:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.264385\tvalid_1's l1: 0.356248\n",
      "[1000]\ttraining's l1: 0.191845\tvalid_1's l1: 0.332462\n",
      "[1500]\ttraining's l1: 0.146798\tvalid_1's l1: 0.321495\n",
      "[2000]\ttraining's l1: 0.116825\tvalid_1's l1: 0.316415\n",
      "[2500]\ttraining's l1: 0.0944691\tvalid_1's l1: 0.313221\n",
      "[3000]\ttraining's l1: 0.0775989\tvalid_1's l1: 0.311207\n",
      "[3500]\ttraining's l1: 0.0642915\tvalid_1's l1: 0.309887\n",
      "[4000]\ttraining's l1: 0.0535053\tvalid_1's l1: 0.30893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's l1: 0.0448155\tvalid_1's l1: 0.308275\n",
      "[5000]\ttraining's l1: 0.0377257\tvalid_1's l1: 0.307806\n",
      "[5500]\ttraining's l1: 0.0319015\tvalid_1's l1: 0.307427\n",
      "[6000]\ttraining's l1: 0.0270154\tvalid_1's l1: 0.307131\n",
      "[6500]\ttraining's l1: 0.0229938\tvalid_1's l1: 0.306911\n",
      "[7000]\ttraining's l1: 0.0196614\tvalid_1's l1: 0.306722\n",
      "[7500]\ttraining's l1: 0.0168808\tvalid_1's l1: 0.306595\n",
      "[8000]\ttraining's l1: 0.014508\tvalid_1's l1: 0.306489\n",
      "[8500]\ttraining's l1: 0.0125456\tvalid_1's l1: 0.306391\n",
      "[9000]\ttraining's l1: 0.0109062\tvalid_1's l1: 0.306319\n",
      "[9500]\ttraining's l1: 0.00949863\tvalid_1's l1: 0.306268\n",
      "[10000]\ttraining's l1: 0.00834099\tvalid_1's l1: 0.306209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00834099\tvalid_1's l1: 0.306209\n",
      "Fold 3 started at Sun Jun  9 14:44:08 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.265349\tvalid_1's l1: 0.357548\n",
      "[1000]\ttraining's l1: 0.191935\tvalid_1's l1: 0.333481\n",
      "[1500]\ttraining's l1: 0.147823\tvalid_1's l1: 0.323223\n",
      "[2000]\ttraining's l1: 0.117574\tvalid_1's l1: 0.317488\n",
      "[2500]\ttraining's l1: 0.0950112\tvalid_1's l1: 0.314564\n",
      "[3000]\ttraining's l1: 0.0777868\tvalid_1's l1: 0.312452\n",
      "[3500]\ttraining's l1: 0.0644285\tvalid_1's l1: 0.311249\n",
      "[4000]\ttraining's l1: 0.0535317\tvalid_1's l1: 0.31042\n",
      "[4500]\ttraining's l1: 0.0446947\tvalid_1's l1: 0.309676\n",
      "[5000]\ttraining's l1: 0.0376214\tvalid_1's l1: 0.309223\n",
      "[5500]\ttraining's l1: 0.0318099\tvalid_1's l1: 0.308827\n",
      "[6000]\ttraining's l1: 0.0269303\tvalid_1's l1: 0.308552\n",
      "[6500]\ttraining's l1: 0.0229289\tvalid_1's l1: 0.308326\n",
      "[7000]\ttraining's l1: 0.0196071\tvalid_1's l1: 0.308132\n",
      "[7500]\ttraining's l1: 0.0168226\tvalid_1's l1: 0.308017\n",
      "[8000]\ttraining's l1: 0.0145043\tvalid_1's l1: 0.307919\n",
      "[8500]\ttraining's l1: 0.0125255\tvalid_1's l1: 0.307837\n",
      "[9000]\ttraining's l1: 0.0108722\tvalid_1's l1: 0.307766\n",
      "[9500]\ttraining's l1: 0.00948125\tvalid_1's l1: 0.307696\n",
      "[10000]\ttraining's l1: 0.00832494\tvalid_1's l1: 0.307659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00832494\tvalid_1's l1: 0.307659\n",
      "Fold 4 started at Sun Jun  9 14:48:38 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.262249\tvalid_1's l1: 0.353264\n",
      "[1000]\ttraining's l1: 0.190837\tvalid_1's l1: 0.331084\n",
      "[1500]\ttraining's l1: 0.148194\tvalid_1's l1: 0.321552\n",
      "[2000]\ttraining's l1: 0.117933\tvalid_1's l1: 0.31624\n",
      "[2500]\ttraining's l1: 0.0958392\tvalid_1's l1: 0.313174\n",
      "[3000]\ttraining's l1: 0.0784343\tvalid_1's l1: 0.311075\n",
      "[3500]\ttraining's l1: 0.0649786\tvalid_1's l1: 0.309817\n",
      "[4000]\ttraining's l1: 0.0542034\tvalid_1's l1: 0.308954\n",
      "[4500]\ttraining's l1: 0.0453255\tvalid_1's l1: 0.308295\n",
      "[5000]\ttraining's l1: 0.038125\tvalid_1's l1: 0.307729\n",
      "[5500]\ttraining's l1: 0.0321728\tvalid_1's l1: 0.307411\n",
      "[6000]\ttraining's l1: 0.0272527\tvalid_1's l1: 0.307104\n",
      "[6500]\ttraining's l1: 0.0232145\tvalid_1's l1: 0.306897\n",
      "[7000]\ttraining's l1: 0.0198217\tvalid_1's l1: 0.306733\n",
      "[7500]\ttraining's l1: 0.0170046\tvalid_1's l1: 0.306614\n",
      "[8000]\ttraining's l1: 0.014647\tvalid_1's l1: 0.306506\n",
      "[8500]\ttraining's l1: 0.0126605\tvalid_1's l1: 0.306416\n",
      "[9000]\ttraining's l1: 0.0109822\tvalid_1's l1: 0.306346\n",
      "[9500]\ttraining's l1: 0.00957009\tvalid_1's l1: 0.306297\n",
      "[10000]\ttraining's l1: 0.00838388\tvalid_1's l1: 0.306253\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00838388\tvalid_1's l1: 0.306253\n",
      "Fold 5 started at Sun Jun  9 14:52:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.263565\tvalid_1's l1: 0.352736\n",
      "[1000]\ttraining's l1: 0.190135\tvalid_1's l1: 0.330271\n",
      "[6500]\ttraining's l1: 0.0230051\tvalid_1's l1: 0.306011\n",
      "[7000]\ttraining's l1: 0.0196654\tvalid_1's l1: 0.305825\n",
      "[7500]\ttraining's l1: 0.0168776\tvalid_1's l1: 0.305701\n",
      "[8000]\ttraining's l1: 0.0145291\tvalid_1's l1: 0.305576\n",
      "[8500]\ttraining's l1: 0.0125657\tvalid_1's l1: 0.305484\n",
      "[9000]\ttraining's l1: 0.0109113\tvalid_1's l1: 0.305431\n",
      "[9500]\ttraining's l1: 0.00951232\tvalid_1's l1: 0.30536\n",
      "[10000]\ttraining's l1: 0.0083481\tvalid_1's l1: 0.305312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0083481\tvalid_1's l1: 0.305312\n",
      "CV mean score: -1.1852, std: 0.0050.\n",
      "Training of type 1\n",
      "Fold 1 started at Sun Jun  9 14:57:19 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.341366\tvalid_1's l1: 0.799903\n",
      "[1000]\ttraining's l1: 0.155461\tvalid_1's l1: 0.778639\n",
      "[1500]\ttraining's l1: 0.079761\tvalid_1's l1: 0.771014\n",
      "[2000]\ttraining's l1: 0.0413945\tvalid_1's l1: 0.768774\n",
      "[2500]\ttraining's l1: 0.0215605\tvalid_1's l1: 0.767671\n",
      "[3000]\ttraining's l1: 0.0111643\tvalid_1's l1: 0.76712\n",
      "[3500]\ttraining's l1: 0.00600824\tvalid_1's l1: 0.766864\n",
      "[4000]\ttraining's l1: 0.00365855\tvalid_1's l1: 0.766761\n",
      "[4500]\ttraining's l1: 0.00265354\tvalid_1's l1: 0.766713\n",
      "[5000]\ttraining's l1: 0.00217407\tvalid_1's l1: 0.766697\n",
      "[5500]\ttraining's l1: 0.00189112\tvalid_1's l1: 0.766686\n",
      "[6000]\ttraining's l1: 0.00170623\tvalid_1's l1: 0.766679\n",
      "[6500]\ttraining's l1: 0.00157466\tvalid_1's l1: 0.76667\n",
      "[7000]\ttraining's l1: 0.00147271\tvalid_1's l1: 0.766663\n",
      "[7500]\ttraining's l1: 0.00139254\tvalid_1's l1: 0.766657\n",
      "[8000]\ttraining's l1: 0.00132549\tvalid_1's l1: 0.766648\n",
      "Early stopping, best iteration is:\n",
      "[8139]\ttraining's l1: 0.00130902\tvalid_1's l1: 0.766648\n",
      "Fold 2 started at Sun Jun  9 14:58:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.344458\tvalid_1's l1: 0.801074\n",
      "[1000]\ttraining's l1: 0.160702\tvalid_1's l1: 0.775854\n",
      "[1500]\ttraining's l1: 0.0831951\tvalid_1's l1: 0.768139\n",
      "[2000]\ttraining's l1: 0.0433229\tvalid_1's l1: 0.7653\n",
      "[2500]\ttraining's l1: 0.0233246\tvalid_1's l1: 0.764044\n",
      "[3000]\ttraining's l1: 0.0121463\tvalid_1's l1: 0.76332\n",
      "[3500]\ttraining's l1: 0.00646588\tvalid_1's l1: 0.763001\n",
      "[4000]\ttraining's l1: 0.00389707\tvalid_1's l1: 0.762903\n",
      "[4500]\ttraining's l1: 0.00278159\tvalid_1's l1: 0.762873\n",
      "[5000]\ttraining's l1: 0.00223775\tvalid_1's l1: 0.762839\n",
      "Early stopping, best iteration is:\n",
      "[4941]\ttraining's l1: 0.00228583\tvalid_1's l1: 0.762837\n",
      "Fold 3 started at Sun Jun  9 14:59:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.331772\tvalid_1's l1: 0.815666\n",
      "[1000]\ttraining's l1: 0.154818\tvalid_1's l1: 0.789592\n",
      "[1500]\ttraining's l1: 0.0790914\tvalid_1's l1: 0.782418\n",
      "[2000]\ttraining's l1: 0.0416341\tvalid_1's l1: 0.779427\n",
      "[2500]\ttraining's l1: 0.0220298\tvalid_1's l1: 0.778276\n",
      "[3000]\ttraining's l1: 0.0116672\tvalid_1's l1: 0.777827\n",
      "[3500]\ttraining's l1: 0.00622383\tvalid_1's l1: 0.777574\n",
      "[4000]\ttraining's l1: 0.00380443\tvalid_1's l1: 0.777486\n",
      "[4500]\ttraining's l1: 0.00273466\tvalid_1's l1: 0.777436\n",
      "[5000]\ttraining's l1: 0.00221905\tvalid_1's l1: 0.777412\n",
      "[5500]\ttraining's l1: 0.00192379\tvalid_1's l1: 0.7774\n",
      "[6000]\ttraining's l1: 0.0017277\tvalid_1's l1: 0.777393\n",
      "[6500]\ttraining's l1: 0.00159389\tvalid_1's l1: 0.777387\n",
      "Early stopping, best iteration is:\n",
      "[6390]\ttraining's l1: 0.00161964\tvalid_1's l1: 0.777385\n",
      "Fold 4 started at Sun Jun  9 15:00:56 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.344384\tvalid_1's l1: 0.787171\n",
      "[1000]\ttraining's l1: 0.160795\tvalid_1's l1: 0.765228\n",
      "[1500]\ttraining's l1: 0.0826863\tvalid_1's l1: 0.758777\n",
      "[2000]\ttraining's l1: 0.0431186\tvalid_1's l1: 0.756866\n",
      "[2500]\ttraining's l1: 0.0225215\tvalid_1's l1: 0.756194\n",
      "[3000]\ttraining's l1: 0.0117368\tvalid_1's l1: 0.755765\n",
      "[3500]\ttraining's l1: 0.00620292\tvalid_1's l1: 0.755568\n",
      "Early stopping, best iteration is:\n",
      "[3761]\ttraining's l1: 0.00467818\tvalid_1's l1: 0.755519\n",
      "Fold 5 started at Sun Jun  9 15:01:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.337934\tvalid_1's l1: 0.815261\n",
      "[1000]\ttraining's l1: 0.160426\tvalid_1's l1: 0.788478\n",
      "[1500]\ttraining's l1: 0.0811551\tvalid_1's l1: 0.780543\n",
      "[2000]\ttraining's l1: 0.0424209\tvalid_1's l1: 0.777246\n",
      "[2500]\ttraining's l1: 0.0224583\tvalid_1's l1: 0.776193\n",
      "[3000]\ttraining's l1: 0.0115374\tvalid_1's l1: 0.775432\n",
      "[3500]\ttraining's l1: 0.00615344\tvalid_1's l1: 0.775165\n",
      "[4000]\ttraining's l1: 0.00374173\tvalid_1's l1: 0.775044\n",
      "[4500]\ttraining's l1: 0.00268872\tvalid_1's l1: 0.774996\n",
      "[5000]\ttraining's l1: 0.0021866\tvalid_1's l1: 0.774966\n",
      "[5500]\ttraining's l1: 0.00189534\tvalid_1's l1: 0.774951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6000]\ttraining's l1: 0.00170905\tvalid_1's l1: 0.774939\n",
      "[6500]\ttraining's l1: 0.00157441\tvalid_1's l1: 0.774933\n",
      "[7000]\ttraining's l1: 0.00147252\tvalid_1's l1: 0.774927\n",
      "[7500]\ttraining's l1: 0.00139234\tvalid_1's l1: 0.774921\n",
      "Early stopping, best iteration is:\n",
      "[7506]\ttraining's l1: 0.00139158\tvalid_1's l1: 0.774921\n",
      "CV mean score: -0.2647, std: 0.0104.\n",
      "Training of type 4\n",
      "Fold 1 started at Sun Jun  9 15:03:01 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.151242\tvalid_1's l1: 0.300783\n",
      "[1000]\ttraining's l1: 0.0852687\tvalid_1's l1: 0.288796\n",
      "[1500]\ttraining's l1: 0.0515278\tvalid_1's l1: 0.28476\n",
      "[2000]\ttraining's l1: 0.0317767\tvalid_1's l1: 0.282879\n",
      "[2500]\ttraining's l1: 0.0201597\tvalid_1's l1: 0.282115\n",
      "[3000]\ttraining's l1: 0.0131542\tvalid_1's l1: 0.281571\n",
      "[3500]\ttraining's l1: 0.00895598\tvalid_1's l1: 0.281342\n",
      "[4000]\ttraining's l1: 0.00632401\tvalid_1's l1: 0.28122\n",
      "[4500]\ttraining's l1: 0.00473522\tvalid_1's l1: 0.281162\n",
      "[5000]\ttraining's l1: 0.00368829\tvalid_1's l1: 0.281127\n",
      "[5500]\ttraining's l1: 0.00300074\tvalid_1's l1: 0.281099\n",
      "[6000]\ttraining's l1: 0.00252789\tvalid_1's l1: 0.281079\n",
      "[6500]\ttraining's l1: 0.00219436\tvalid_1's l1: 0.281069\n",
      "[7000]\ttraining's l1: 0.00195511\tvalid_1's l1: 0.281067\n",
      "Early stopping, best iteration is:\n",
      "[7217]\ttraining's l1: 0.0018753\tvalid_1's l1: 0.281063\n",
      "Fold 2 started at Sun Jun  9 15:04:50 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.152773\tvalid_1's l1: 0.304405\n",
      "[1000]\ttraining's l1: 0.0843447\tvalid_1's l1: 0.291371\n",
      "[1500]\ttraining's l1: 0.0508063\tvalid_1's l1: 0.287287\n",
      "[2000]\ttraining's l1: 0.0319118\tvalid_1's l1: 0.285384\n",
      "[2500]\ttraining's l1: 0.0205696\tvalid_1's l1: 0.284496\n",
      "[3000]\ttraining's l1: 0.013845\tvalid_1's l1: 0.284044\n",
      "[3500]\ttraining's l1: 0.00966789\tvalid_1's l1: 0.283781\n",
      "[4000]\ttraining's l1: 0.00709673\tvalid_1's l1: 0.283626\n",
      "[4500]\ttraining's l1: 0.00537684\tvalid_1's l1: 0.283542\n",
      "[5000]\ttraining's l1: 0.00422551\tvalid_1's l1: 0.283504\n",
      "[5500]\ttraining's l1: 0.00340777\tvalid_1's l1: 0.283461\n",
      "[6000]\ttraining's l1: 0.00276675\tvalid_1's l1: 0.283438\n",
      "[6500]\ttraining's l1: 0.00228159\tvalid_1's l1: 0.283413\n",
      "[7000]\ttraining's l1: 0.00193039\tvalid_1's l1: 0.2834\n",
      "[7500]\ttraining's l1: 0.0016799\tvalid_1's l1: 0.283391\n",
      "[8000]\ttraining's l1: 0.00150045\tvalid_1's l1: 0.283384\n",
      "Early stopping, best iteration is:\n",
      "[8280]\ttraining's l1: 0.00142215\tvalid_1's l1: 0.283382\n",
      "Fold 3 started at Sun Jun  9 15:06:59 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.154337\tvalid_1's l1: 0.308026\n",
      "[1000]\ttraining's l1: 0.0860633\tvalid_1's l1: 0.294146\n",
      "[1500]\ttraining's l1: 0.0512994\tvalid_1's l1: 0.289841\n",
      "[2000]\ttraining's l1: 0.0316748\tvalid_1's l1: 0.287882\n",
      "[2500]\ttraining's l1: 0.0200229\tvalid_1's l1: 0.286899\n",
      "[3000]\ttraining's l1: 0.0130242\tvalid_1's l1: 0.286379\n",
      "[3500]\ttraining's l1: 0.00870897\tvalid_1's l1: 0.286069\n",
      "[4000]\ttraining's l1: 0.00609015\tvalid_1's l1: 0.285952\n",
      "[4500]\ttraining's l1: 0.00446288\tvalid_1's l1: 0.285879\n",
      "[5000]\ttraining's l1: 0.00343552\tvalid_1's l1: 0.285826\n",
      "[5500]\ttraining's l1: 0.00276809\tvalid_1's l1: 0.285795\n",
      "[6000]\ttraining's l1: 0.00232135\tvalid_1's l1: 0.285768\n",
      "[6500]\ttraining's l1: 0.00201178\tvalid_1's l1: 0.285753\n",
      "[7000]\ttraining's l1: 0.00178833\tvalid_1's l1: 0.285743\n",
      "[7500]\ttraining's l1: 0.00161248\tvalid_1's l1: 0.285732\n",
      "[8000]\ttraining's l1: 0.00146624\tvalid_1's l1: 0.285725\n",
      "[8500]\ttraining's l1: 0.00134632\tvalid_1's l1: 0.285721\n",
      "[9000]\ttraining's l1: 0.00125379\tvalid_1's l1: 0.285716\n",
      "[9500]\ttraining's l1: 0.0011802\tvalid_1's l1: 0.285711\n",
      "Early stopping, best iteration is:\n",
      "[9546]\ttraining's l1: 0.00117416\tvalid_1's l1: 0.285711\n",
      "Fold 4 started at Sun Jun  9 15:09:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.150856\tvalid_1's l1: 0.30371\n",
      "[1000]\ttraining's l1: 0.0849529\tvalid_1's l1: 0.291771\n",
      "[1500]\ttraining's l1: 0.0511042\tvalid_1's l1: 0.288104\n",
      "[2000]\ttraining's l1: 0.0320314\tvalid_1's l1: 0.28632\n",
      "[2500]\ttraining's l1: 0.0201788\tvalid_1's l1: 0.285473\n",
      "[3000]\ttraining's l1: 0.013092\tvalid_1's l1: 0.285012\n",
      "[3500]\ttraining's l1: 0.00879607\tvalid_1's l1: 0.284789\n",
      "[4000]\ttraining's l1: 0.00613946\tvalid_1's l1: 0.284643\n",
      "[4500]\ttraining's l1: 0.00451216\tvalid_1's l1: 0.284562\n",
      "[5000]\ttraining's l1: 0.00346081\tvalid_1's l1: 0.284501\n",
      "[5500]\ttraining's l1: 0.0027652\tvalid_1's l1: 0.284461\n",
      "[6000]\ttraining's l1: 0.00229335\tvalid_1's l1: 0.284434\n",
      "[6500]\ttraining's l1: 0.0019615\tvalid_1's l1: 0.284418\n",
      "[7000]\ttraining's l1: 0.00172982\tvalid_1's l1: 0.284409\n",
      "[7500]\ttraining's l1: 0.00156409\tvalid_1's l1: 0.284402\n",
      "[8000]\ttraining's l1: 0.00143843\tvalid_1's l1: 0.284397\n",
      "[8500]\ttraining's l1: 0.00134042\tvalid_1's l1: 0.284392\n",
      "[9000]\ttraining's l1: 0.00125758\tvalid_1's l1: 0.284388\n",
      "[9500]\ttraining's l1: 0.00118822\tvalid_1's l1: 0.284385\n",
      "[10000]\ttraining's l1: 0.00113232\tvalid_1's l1: 0.284382\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00113232\tvalid_1's l1: 0.284382\n",
      "Fold 5 started at Sun Jun  9 15:11:53 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.150082\tvalid_1's l1: 0.301837\n",
      "[1000]\ttraining's l1: 0.0843511\tvalid_1's l1: 0.28955\n",
      "[1500]\ttraining's l1: 0.0501502\tvalid_1's l1: 0.285434\n",
      "[2000]\ttraining's l1: 0.0312653\tvalid_1's l1: 0.283404\n",
      "[2500]\ttraining's l1: 0.0198909\tvalid_1's l1: 0.282565\n",
      "[3000]\ttraining's l1: 0.0129005\tvalid_1's l1: 0.282156\n",
      "[3500]\ttraining's l1: 0.00869696\tvalid_1's l1: 0.281902\n",
      "[4000]\ttraining's l1: 0.00609355\tvalid_1's l1: 0.281789\n",
      "[4500]\ttraining's l1: 0.00449682\tvalid_1's l1: 0.281719\n",
      "[5000]\ttraining's l1: 0.00347284\tvalid_1's l1: 0.281682\n",
      "[5500]\ttraining's l1: 0.00279567\tvalid_1's l1: 0.28165\n",
      "[6000]\ttraining's l1: 0.00234338\tvalid_1's l1: 0.281635\n",
      "[6500]\ttraining's l1: 0.00203832\tvalid_1's l1: 0.281624\n",
      "[7000]\ttraining's l1: 0.0018407\tvalid_1's l1: 0.281616\n",
      "[7500]\ttraining's l1: 0.00169477\tvalid_1's l1: 0.28161\n",
      "[8000]\ttraining's l1: 0.00159331\tvalid_1's l1: 0.281603\n",
      "Early stopping, best iteration is:\n",
      "[8259]\ttraining's l1: 0.00154885\tvalid_1's l1: 0.2816\n",
      "CV mean score: -1.2615, std: 0.0061.\n",
      "Training of type 2\n",
      "Fold 1 started at Sun Jun  9 15:13:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.571978\tvalid_1's l1: 0.646475\n",
      "[1000]\ttraining's l1: 0.489103\tvalid_1's l1: 0.617464\n",
      "[1500]\ttraining's l1: 0.425156\tvalid_1's l1: 0.596712\n",
      "[2000]\ttraining's l1: 0.374942\tvalid_1's l1: 0.581956\n",
      "[2500]\ttraining's l1: 0.334355\tvalid_1's l1: 0.571859\n",
      "[3000]\ttraining's l1: 0.300255\tvalid_1's l1: 0.5635\n",
      "[3500]\ttraining's l1: 0.271349\tvalid_1's l1: 0.557052\n",
      "[4000]\ttraining's l1: 0.246266\tvalid_1's l1: 0.552097\n",
      "[4500]\ttraining's l1: 0.224551\tvalid_1's l1: 0.548002\n",
      "[5000]\ttraining's l1: 0.205407\tvalid_1's l1: 0.544646\n",
      "[5500]\ttraining's l1: 0.188408\tvalid_1's l1: 0.541945\n",
      "[6000]\ttraining's l1: 0.173206\tvalid_1's l1: 0.539509\n",
      "[6500]\ttraining's l1: 0.15962\tvalid_1's l1: 0.537503\n",
      "[7000]\ttraining's l1: 0.147273\tvalid_1's l1: 0.535748\n",
      "[7500]\ttraining's l1: 0.136143\tvalid_1's l1: 0.534304\n",
      "[8000]\ttraining's l1: 0.125956\tvalid_1's l1: 0.53293\n",
      "[8500]\ttraining's l1: 0.11683\tvalid_1's l1: 0.531812\n",
      "[9000]\ttraining's l1: 0.108445\tvalid_1's l1: 0.53091\n",
      "[9500]\ttraining's l1: 0.100866\tvalid_1's l1: 0.530121\n",
      "[10000]\ttraining's l1: 0.093838\tvalid_1's l1: 0.529431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.093838\tvalid_1's l1: 0.529431\n",
      "Fold 2 started at Sun Jun  9 15:19:56 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.575205\tvalid_1's l1: 0.647561\n",
      "[1000]\ttraining's l1: 0.489786\tvalid_1's l1: 0.616982\n",
      "[1500]\ttraining's l1: 0.42548\tvalid_1's l1: 0.596419\n",
      "[2000]\ttraining's l1: 0.374957\tvalid_1's l1: 0.582183\n",
      "[2500]\ttraining's l1: 0.333994\tvalid_1's l1: 0.571211\n",
      "[3000]\ttraining's l1: 0.299905\tvalid_1's l1: 0.562979\n",
      "[3500]\ttraining's l1: 0.270879\tvalid_1's l1: 0.556384\n",
      "[4000]\ttraining's l1: 0.245965\tvalid_1's l1: 0.551374\n",
      "[4500]\ttraining's l1: 0.224261\tvalid_1's l1: 0.547296\n",
      "[5000]\ttraining's l1: 0.205045\tvalid_1's l1: 0.543929\n",
      "[5500]\ttraining's l1: 0.188211\tvalid_1's l1: 0.541291\n",
      "[6000]\ttraining's l1: 0.173134\tvalid_1's l1: 0.53902\n",
      "[6500]\ttraining's l1: 0.159426\tvalid_1's l1: 0.53716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7000]\ttraining's l1: 0.147198\tvalid_1's l1: 0.535459\n",
      "[7500]\ttraining's l1: 0.136107\tvalid_1's l1: 0.534111\n",
      "[8000]\ttraining's l1: 0.126059\tvalid_1's l1: 0.53288\n",
      "[8500]\ttraining's l1: 0.116847\tvalid_1's l1: 0.53182\n",
      "[9000]\ttraining's l1: 0.108439\tvalid_1's l1: 0.530922\n",
      "[9500]\ttraining's l1: 0.100719\tvalid_1's l1: 0.530092\n",
      "[10000]\ttraining's l1: 0.0936075\tvalid_1's l1: 0.529335\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0936075\tvalid_1's l1: 0.529335\n",
      "Fold 3 started at Sun Jun  9 15:26:07 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.572911\tvalid_1's l1: 0.649735\n",
      "[1000]\ttraining's l1: 0.488002\tvalid_1's l1: 0.618528\n",
      "[1500]\ttraining's l1: 0.423814\tvalid_1's l1: 0.597557\n",
      "[2000]\ttraining's l1: 0.373397\tvalid_1's l1: 0.58326\n",
      "[2500]\ttraining's l1: 0.333175\tvalid_1's l1: 0.572775\n",
      "[3000]\ttraining's l1: 0.29912\tvalid_1's l1: 0.564557\n",
      "[3500]\ttraining's l1: 0.270255\tvalid_1's l1: 0.55837\n",
      "[4000]\ttraining's l1: 0.245371\tvalid_1's l1: 0.553627\n",
      "[7500]\ttraining's l1: 0.13556\tvalid_1's l1: 0.536468\n",
      "[8000]\ttraining's l1: 0.125504\tvalid_1's l1: 0.535322\n",
      "[8500]\ttraining's l1: 0.116367\tvalid_1's l1: 0.53421\n",
      "[9000]\ttraining's l1: 0.107925\tvalid_1's l1: 0.533367\n",
      "[9500]\ttraining's l1: 0.10032\tvalid_1's l1: 0.532532\n",
      "[10000]\ttraining's l1: 0.0932935\tvalid_1's l1: 0.531869\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0932935\tvalid_1's l1: 0.531869\n",
      "Fold 4 started at Sun Jun  9 15:32:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.574097\tvalid_1's l1: 0.646401\n",
      "[1000]\ttraining's l1: 0.488854\tvalid_1's l1: 0.616321\n",
      "[1500]\ttraining's l1: 0.425925\tvalid_1's l1: 0.596303\n",
      "[2000]\ttraining's l1: 0.374932\tvalid_1's l1: 0.58061\n",
      "[2500]\ttraining's l1: 0.333752\tvalid_1's l1: 0.569886\n",
      "[3000]\ttraining's l1: 0.299567\tvalid_1's l1: 0.561439\n",
      "[3500]\ttraining's l1: 0.270781\tvalid_1's l1: 0.555164\n",
      "[4000]\ttraining's l1: 0.24586\tvalid_1's l1: 0.55032\n",
      "[4500]\ttraining's l1: 0.224343\tvalid_1's l1: 0.54656\n",
      "[5000]\ttraining's l1: 0.205054\tvalid_1's l1: 0.543192\n",
      "[5500]\ttraining's l1: 0.18808\tvalid_1's l1: 0.540471\n",
      "[6000]\ttraining's l1: 0.17287\tvalid_1's l1: 0.538139\n",
      "[6500]\ttraining's l1: 0.159327\tvalid_1's l1: 0.536349\n",
      "[7000]\ttraining's l1: 0.14712\tvalid_1's l1: 0.534807\n",
      "[7500]\ttraining's l1: 0.136032\tvalid_1's l1: 0.533456\n",
      "[8000]\ttraining's l1: 0.125951\tvalid_1's l1: 0.532366\n",
      "[8500]\ttraining's l1: 0.116717\tvalid_1's l1: 0.531241\n",
      "[9000]\ttraining's l1: 0.108326\tvalid_1's l1: 0.53027\n",
      "[9500]\ttraining's l1: 0.100604\tvalid_1's l1: 0.529468\n",
      "[10000]\ttraining's l1: 0.0935628\tvalid_1's l1: 0.528733\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0935628\tvalid_1's l1: 0.528733\n",
      "Fold 5 started at Sun Jun  9 15:38:17 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.574581\tvalid_1's l1: 0.648011\n",
      "[3500]\ttraining's l1: 0.270411\tvalid_1's l1: 0.557487\n",
      "[4000]\ttraining's l1: 0.245553\tvalid_1's l1: 0.552694\n",
      "[4500]\ttraining's l1: 0.223867\tvalid_1's l1: 0.548513\n",
      "[5000]\ttraining's l1: 0.204606\tvalid_1's l1: 0.545062\n",
      "[5500]\ttraining's l1: 0.187703\tvalid_1's l1: 0.542402\n",
      "[6000]\ttraining's l1: 0.172655\tvalid_1's l1: 0.540232\n",
      "[6500]\ttraining's l1: 0.1591\tvalid_1's l1: 0.538337\n",
      "[7000]\ttraining's l1: 0.146807\tvalid_1's l1: 0.536767\n",
      "[7500]\ttraining's l1: 0.135765\tvalid_1's l1: 0.535296\n",
      "[8000]\ttraining's l1: 0.125693\tvalid_1's l1: 0.534033\n",
      "[8500]\ttraining's l1: 0.116525\tvalid_1's l1: 0.532858\n",
      "[9000]\ttraining's l1: 0.108113\tvalid_1's l1: 0.532042\n",
      "[9500]\ttraining's l1: 0.100454\tvalid_1's l1: 0.531209\n",
      "[10000]\ttraining's l1: 0.0934404\tvalid_1's l1: 0.530523\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0934404\tvalid_1's l1: 0.530523\n",
      "CV mean score: -0.6349, std: 0.0021.\n",
      "Training of type 6\n",
      "Fold 1 started at Sun Jun  9 15:44:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.272604\tvalid_1's l1: 0.335733\n",
      "[1000]\ttraining's l1: 0.208609\tvalid_1's l1: 0.310256\n",
      "[1500]\ttraining's l1: 0.169099\tvalid_1's l1: 0.298352\n",
      "[2000]\ttraining's l1: 0.140806\tvalid_1's l1: 0.291833\n",
      "[2500]\ttraining's l1: 0.119191\tvalid_1's l1: 0.287486\n",
      "[3000]\ttraining's l1: 0.102257\tvalid_1's l1: 0.284611\n",
      "[3500]\ttraining's l1: 0.0884197\tvalid_1's l1: 0.282399\n",
      "[4000]\ttraining's l1: 0.0769072\tvalid_1's l1: 0.280805\n",
      "[4500]\ttraining's l1: 0.067241\tvalid_1's l1: 0.279598\n",
      "[5000]\ttraining's l1: 0.0590993\tvalid_1's l1: 0.278659\n",
      "[5500]\ttraining's l1: 0.0520869\tvalid_1's l1: 0.277971\n",
      "[6000]\ttraining's l1: 0.0460206\tvalid_1's l1: 0.277417\n",
      "[6500]\ttraining's l1: 0.0407814\tvalid_1's l1: 0.276964\n",
      "[7000]\ttraining's l1: 0.0362491\tvalid_1's l1: 0.276587\n",
      "[7500]\ttraining's l1: 0.0322904\tvalid_1's l1: 0.276301\n",
      "[8000]\ttraining's l1: 0.028832\tvalid_1's l1: 0.276054\n",
      "[8500]\ttraining's l1: 0.0258215\tvalid_1's l1: 0.275811\n",
      "[9000]\ttraining's l1: 0.0231609\tvalid_1's l1: 0.27562\n",
      "[9500]\ttraining's l1: 0.0208\tvalid_1's l1: 0.275453\n",
      "[10000]\ttraining's l1: 0.0187389\tvalid_1's l1: 0.275311\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0187389\tvalid_1's l1: 0.275311\n",
      "Fold 2 started at Sun Jun  9 15:49:31 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.272919\tvalid_1's l1: 0.335333\n",
      "[1000]\ttraining's l1: 0.209849\tvalid_1's l1: 0.311231\n",
      "[1500]\ttraining's l1: 0.16906\tvalid_1's l1: 0.298617\n",
      "[2000]\ttraining's l1: 0.14073\tvalid_1's l1: 0.291911\n",
      "[2500]\ttraining's l1: 0.119175\tvalid_1's l1: 0.287432\n",
      "[3000]\ttraining's l1: 0.102315\tvalid_1's l1: 0.284391\n",
      "[3500]\ttraining's l1: 0.0885131\tvalid_1's l1: 0.282269\n",
      "[4000]\ttraining's l1: 0.0770521\tvalid_1's l1: 0.280645\n",
      "[4500]\ttraining's l1: 0.0674056\tvalid_1's l1: 0.279517\n",
      "[5000]\ttraining's l1: 0.0591956\tvalid_1's l1: 0.278528\n",
      "[5500]\ttraining's l1: 0.0521862\tvalid_1's l1: 0.277831\n",
      "[6000]\ttraining's l1: 0.0461637\tvalid_1's l1: 0.277199\n",
      "[6500]\ttraining's l1: 0.0409597\tvalid_1's l1: 0.276714\n",
      "[7000]\ttraining's l1: 0.0363984\tvalid_1's l1: 0.27636\n",
      "[7500]\ttraining's l1: 0.0324491\tvalid_1's l1: 0.276044\n",
      "[8000]\ttraining's l1: 0.0289845\tvalid_1's l1: 0.27579\n",
      "[8500]\ttraining's l1: 0.0259329\tvalid_1's l1: 0.275566\n",
      "[9000]\ttraining's l1: 0.0232662\tvalid_1's l1: 0.275361\n",
      "[9500]\ttraining's l1: 0.0208958\tvalid_1's l1: 0.275193\n",
      "[10000]\ttraining's l1: 0.0188112\tvalid_1's l1: 0.275048\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0188112\tvalid_1's l1: 0.275048\n",
      "Fold 3 started at Sun Jun  9 15:54:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.27325\tvalid_1's l1: 0.337914\n",
      "[1000]\ttraining's l1: 0.208833\tvalid_1's l1: 0.312669\n",
      "[1500]\ttraining's l1: 0.168673\tvalid_1's l1: 0.300328\n",
      "[2000]\ttraining's l1: 0.14048\tvalid_1's l1: 0.293358\n",
      "[2500]\ttraining's l1: 0.118918\tvalid_1's l1: 0.289059\n",
      "[3000]\ttraining's l1: 0.101951\tvalid_1's l1: 0.286326\n",
      "[3500]\ttraining's l1: 0.0880917\tvalid_1's l1: 0.284371\n",
      "[4000]\ttraining's l1: 0.0765947\tvalid_1's l1: 0.282859\n",
      "[4500]\ttraining's l1: 0.0670081\tvalid_1's l1: 0.28182\n",
      "[5000]\ttraining's l1: 0.0588247\tvalid_1's l1: 0.280935\n",
      "[5500]\ttraining's l1: 0.0518093\tvalid_1's l1: 0.280281\n",
      "[6000]\ttraining's l1: 0.0457544\tvalid_1's l1: 0.279724\n",
      "[6500]\ttraining's l1: 0.0405779\tvalid_1's l1: 0.27928\n",
      "[7000]\ttraining's l1: 0.0360677\tvalid_1's l1: 0.278924\n",
      "[7500]\ttraining's l1: 0.0321185\tvalid_1's l1: 0.278568\n",
      "[8000]\ttraining's l1: 0.0286873\tvalid_1's l1: 0.278302\n",
      "[8500]\ttraining's l1: 0.0256971\tvalid_1's l1: 0.278106\n",
      "[9000]\ttraining's l1: 0.0230165\tvalid_1's l1: 0.277911\n",
      "[9500]\ttraining's l1: 0.0206946\tvalid_1's l1: 0.277741\n",
      "[10000]\ttraining's l1: 0.0186353\tvalid_1's l1: 0.277597\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0186353\tvalid_1's l1: 0.277597\n",
      "Fold 4 started at Sun Jun  9 15:59:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.271757\tvalid_1's l1: 0.334185\n",
      "[1000]\ttraining's l1: 0.207867\tvalid_1's l1: 0.308479\n",
      "[1500]\ttraining's l1: 0.168676\tvalid_1's l1: 0.296644\n",
      "[2000]\ttraining's l1: 0.140758\tvalid_1's l1: 0.290104\n",
      "[2500]\ttraining's l1: 0.119197\tvalid_1's l1: 0.285892\n",
      "[3000]\ttraining's l1: 0.102279\tvalid_1's l1: 0.283371\n",
      "[3500]\ttraining's l1: 0.0884278\tvalid_1's l1: 0.281304\n",
      "[4000]\ttraining's l1: 0.0769993\tvalid_1's l1: 0.279849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's l1: 0.06734\tvalid_1's l1: 0.278761\n",
      "[5000]\ttraining's l1: 0.0591526\tvalid_1's l1: 0.277845\n",
      "[5500]\ttraining's l1: 0.0521366\tvalid_1's l1: 0.277107\n",
      "[6000]\ttraining's l1: 0.0460583\tvalid_1's l1: 0.276559\n",
      "[6500]\ttraining's l1: 0.0408439\tvalid_1's l1: 0.276133\n",
      "[7000]\ttraining's l1: 0.036367\tvalid_1's l1: 0.275768\n",
      "[7500]\ttraining's l1: 0.0324444\tvalid_1's l1: 0.27551\n",
      "[8000]\ttraining's l1: 0.0289656\tvalid_1's l1: 0.275257\n",
      "[8500]\ttraining's l1: 0.025915\tvalid_1's l1: 0.27506\n",
      "[9000]\ttraining's l1: 0.0232508\tvalid_1's l1: 0.274882\n",
      "[9500]\ttraining's l1: 0.020905\tvalid_1's l1: 0.274715\n",
      "[10000]\ttraining's l1: 0.0188335\tvalid_1's l1: 0.274592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0188335\tvalid_1's l1: 0.274592\n",
      "Fold 5 started at Sun Jun  9 16:04:48 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.273996\tvalid_1's l1: 0.337295\n",
      "[1000]\ttraining's l1: 0.209368\tvalid_1's l1: 0.310392\n",
      "[1500]\ttraining's l1: 0.169157\tvalid_1's l1: 0.297806\n",
      "[2000]\ttraining's l1: 0.140877\tvalid_1's l1: 0.291026\n",
      "[2500]\ttraining's l1: 0.119201\tvalid_1's l1: 0.28653\n",
      "[3000]\ttraining's l1: 0.102068\tvalid_1's l1: 0.2835\n",
      "[3500]\ttraining's l1: 0.0882259\tvalid_1's l1: 0.281535\n",
      "[4000]\ttraining's l1: 0.0768563\tvalid_1's l1: 0.280026\n",
      "[4500]\ttraining's l1: 0.0672083\tvalid_1's l1: 0.278969\n",
      "[5000]\ttraining's l1: 0.059037\tvalid_1's l1: 0.27805\n",
      "[5500]\ttraining's l1: 0.0520834\tvalid_1's l1: 0.277368\n",
      "[6000]\ttraining's l1: 0.0460075\tvalid_1's l1: 0.27681\n",
      "[6500]\ttraining's l1: 0.0408189\tvalid_1's l1: 0.276391\n",
      "[7000]\ttraining's l1: 0.0363151\tvalid_1's l1: 0.276028\n",
      "[7500]\ttraining's l1: 0.0323577\tvalid_1's l1: 0.275727\n",
      "[8000]\ttraining's l1: 0.0289115\tvalid_1's l1: 0.275515\n",
      "[8500]\ttraining's l1: 0.0258733\tvalid_1's l1: 0.275295\n",
      "[9000]\ttraining's l1: 0.0232107\tvalid_1's l1: 0.27511\n",
      "[9500]\ttraining's l1: 0.0208579\tvalid_1's l1: 0.274948\n",
      "[10000]\ttraining's l1: 0.0187765\tvalid_1's l1: 0.274803\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0187765\tvalid_1's l1: 0.274803\n",
      "CV mean score: -1.2893, std: 0.0039.\n",
      "Training of type 5\n",
      "Fold 1 started at Sun Jun  9 16:10:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.572279\tvalid_1's l1: 0.623411\n",
      "[1000]\ttraining's l1: 0.50684\tvalid_1's l1: 0.600215\n",
      "[1500]\ttraining's l1: 0.456057\tvalid_1's l1: 0.584318\n",
      "[2000]\ttraining's l1: 0.412975\tvalid_1's l1: 0.571218\n",
      "[2500]\ttraining's l1: 0.376388\tvalid_1's l1: 0.560736\n",
      "[3000]\ttraining's l1: 0.345437\tvalid_1's l1: 0.553138\n",
      "[3500]\ttraining's l1: 0.318117\tvalid_1's l1: 0.546442\n",
      "[4000]\ttraining's l1: 0.293974\tvalid_1's l1: 0.541077\n",
      "[4500]\ttraining's l1: 0.272344\tvalid_1's l1: 0.536416\n",
      "[5000]\ttraining's l1: 0.253183\tvalid_1's l1: 0.532701\n",
      "[5500]\ttraining's l1: 0.235838\tvalid_1's l1: 0.529436\n",
      "[6000]\ttraining's l1: 0.219968\tvalid_1's l1: 0.526409\n",
      "[6500]\ttraining's l1: 0.205723\tvalid_1's l1: 0.523784\n",
      "[7000]\ttraining's l1: 0.192661\tvalid_1's l1: 0.521573\n",
      "[7500]\ttraining's l1: 0.180631\tvalid_1's l1: 0.519611\n",
      "[8000]\ttraining's l1: 0.169612\tvalid_1's l1: 0.517947\n",
      "[8500]\ttraining's l1: 0.159424\tvalid_1's l1: 0.516572\n",
      "[9000]\ttraining's l1: 0.150029\tvalid_1's l1: 0.515333\n",
      "[9500]\ttraining's l1: 0.141327\tvalid_1's l1: 0.514127\n",
      "[10000]\ttraining's l1: 0.133189\tvalid_1's l1: 0.513038\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.133189\tvalid_1's l1: 0.513038\n",
      "Fold 2 started at Sun Jun  9 16:17:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.56993\tvalid_1's l1: 0.6258\n",
      "[1000]\ttraining's l1: 0.505774\tvalid_1's l1: 0.60298\n",
      "[1500]\ttraining's l1: 0.454484\tvalid_1's l1: 0.586336\n",
      "[2000]\ttraining's l1: 0.412204\tvalid_1's l1: 0.573681\n",
      "[2500]\ttraining's l1: 0.376241\tvalid_1's l1: 0.563614\n",
      "[3000]\ttraining's l1: 0.345228\tvalid_1's l1: 0.555796\n",
      "[3500]\ttraining's l1: 0.317998\tvalid_1's l1: 0.549004\n",
      "[4000]\ttraining's l1: 0.29385\tvalid_1's l1: 0.543495\n",
      "[4500]\ttraining's l1: 0.272635\tvalid_1's l1: 0.539136\n",
      "[5000]\ttraining's l1: 0.253256\tvalid_1's l1: 0.535142\n",
      "[5500]\ttraining's l1: 0.235893\tvalid_1's l1: 0.531633\n",
      "[6000]\ttraining's l1: 0.220007\tvalid_1's l1: 0.528563\n",
      "[6500]\ttraining's l1: 0.205772\tvalid_1's l1: 0.526079\n",
      "[7000]\ttraining's l1: 0.192798\tvalid_1's l1: 0.524077\n",
      "[7500]\ttraining's l1: 0.18089\tvalid_1's l1: 0.522153\n",
      "[8000]\ttraining's l1: 0.169903\tvalid_1's l1: 0.52051\n",
      "[8500]\ttraining's l1: 0.159576\tvalid_1's l1: 0.518978\n",
      "[9000]\ttraining's l1: 0.150103\tvalid_1's l1: 0.517585\n",
      "[9500]\ttraining's l1: 0.141331\tvalid_1's l1: 0.516413\n",
      "[10000]\ttraining's l1: 0.133253\tvalid_1's l1: 0.515384\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.133253\tvalid_1's l1: 0.515384\n",
      "Fold 3 started at Sun Jun  9 16:25:06 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.572132\tvalid_1's l1: 0.623961\n",
      "[1000]\ttraining's l1: 0.506261\tvalid_1's l1: 0.599373\n",
      "[1500]\ttraining's l1: 0.455263\tvalid_1's l1: 0.583646\n",
      "[2000]\ttraining's l1: 0.41282\tvalid_1's l1: 0.570989\n",
      "[2500]\ttraining's l1: 0.376918\tvalid_1's l1: 0.561367\n",
      "[3000]\ttraining's l1: 0.345632\tvalid_1's l1: 0.553512\n",
      "[3500]\ttraining's l1: 0.318321\tvalid_1's l1: 0.54695\n",
      "[4000]\ttraining's l1: 0.294219\tvalid_1's l1: 0.541193\n",
      "[4500]\ttraining's l1: 0.272589\tvalid_1's l1: 0.536687\n",
      "[5000]\ttraining's l1: 0.253353\tvalid_1's l1: 0.533\n",
      "[5500]\ttraining's l1: 0.236025\tvalid_1's l1: 0.529738\n",
      "[6000]\ttraining's l1: 0.220237\tvalid_1's l1: 0.526708\n",
      "[6500]\ttraining's l1: 0.206008\tvalid_1's l1: 0.524276\n",
      "[7000]\ttraining's l1: 0.192992\tvalid_1's l1: 0.522152\n",
      "[7500]\ttraining's l1: 0.180941\tvalid_1's l1: 0.520204\n",
      "[8000]\ttraining's l1: 0.169986\tvalid_1's l1: 0.518582\n",
      "[8500]\ttraining's l1: 0.159757\tvalid_1's l1: 0.517089\n",
      "[9000]\ttraining's l1: 0.150306\tvalid_1's l1: 0.5158\n",
      "[9500]\ttraining's l1: 0.141508\tvalid_1's l1: 0.51465\n",
      "[10000]\ttraining's l1: 0.133416\tvalid_1's l1: 0.513666\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.133416\tvalid_1's l1: 0.513666\n",
      "Fold 4 started at Sun Jun  9 16:32:21 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.571257\tvalid_1's l1: 0.625351\n",
      "[1000]\ttraining's l1: 0.50722\tvalid_1's l1: 0.60228\n",
      "[1500]\ttraining's l1: 0.456439\tvalid_1's l1: 0.5864\n",
      "[2000]\ttraining's l1: 0.413434\tvalid_1's l1: 0.573482\n",
      "[2500]\ttraining's l1: 0.377714\tvalid_1's l1: 0.563713\n",
      "[3000]\ttraining's l1: 0.346203\tvalid_1's l1: 0.55543\n",
      "[3500]\ttraining's l1: 0.318724\tvalid_1's l1: 0.548667\n",
      "[4000]\ttraining's l1: 0.294474\tvalid_1's l1: 0.543077\n",
      "[4500]\ttraining's l1: 0.273101\tvalid_1's l1: 0.538631\n",
      "[5000]\ttraining's l1: 0.25391\tvalid_1's l1: 0.534668\n",
      "[5500]\ttraining's l1: 0.236341\tvalid_1's l1: 0.531149\n",
      "[6000]\ttraining's l1: 0.220459\tvalid_1's l1: 0.527885\n",
      "[6500]\ttraining's l1: 0.20612\tvalid_1's l1: 0.525387\n",
      "[7000]\ttraining's l1: 0.193027\tvalid_1's l1: 0.523323\n",
      "[7500]\ttraining's l1: 0.18086\tvalid_1's l1: 0.521148\n",
      "[8000]\ttraining's l1: 0.169822\tvalid_1's l1: 0.51941\n",
      "[8500]\ttraining's l1: 0.159577\tvalid_1's l1: 0.517814\n",
      "[9000]\ttraining's l1: 0.150167\tvalid_1's l1: 0.51645\n",
      "[9500]\ttraining's l1: 0.141446\tvalid_1's l1: 0.515243\n",
      "[10000]\ttraining's l1: 0.133348\tvalid_1's l1: 0.514239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.133348\tvalid_1's l1: 0.514239\n",
      "Fold 5 started at Sun Jun  9 16:39:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.569731\tvalid_1's l1: 0.624839\n",
      "[1000]\ttraining's l1: 0.504484\tvalid_1's l1: 0.600953\n",
      "[1500]\ttraining's l1: 0.454807\tvalid_1's l1: 0.585883\n",
      "[2000]\ttraining's l1: 0.411912\tvalid_1's l1: 0.572864\n",
      "[2500]\ttraining's l1: 0.375648\tvalid_1's l1: 0.562229\n",
      "[3000]\ttraining's l1: 0.344627\tvalid_1's l1: 0.554405\n",
      "[3500]\ttraining's l1: 0.317459\tvalid_1's l1: 0.547916\n",
      "[4000]\ttraining's l1: 0.293207\tvalid_1's l1: 0.542262\n",
      "[4500]\ttraining's l1: 0.271676\tvalid_1's l1: 0.537481\n",
      "[5000]\ttraining's l1: 0.252329\tvalid_1's l1: 0.533647\n",
      "[5500]\ttraining's l1: 0.235001\tvalid_1's l1: 0.530227\n",
      "[6000]\ttraining's l1: 0.219637\tvalid_1's l1: 0.527499\n",
      "[6500]\ttraining's l1: 0.205344\tvalid_1's l1: 0.524854\n",
      "[7000]\ttraining's l1: 0.192327\tvalid_1's l1: 0.522768\n",
      "[7500]\ttraining's l1: 0.180345\tvalid_1's l1: 0.520894\n",
      "[8000]\ttraining's l1: 0.169351\tvalid_1's l1: 0.519247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8500]\ttraining's l1: 0.15921\tvalid_1's l1: 0.517846\n",
      "[9000]\ttraining's l1: 0.149783\tvalid_1's l1: 0.516482\n",
      "[9500]\ttraining's l1: 0.141163\tvalid_1's l1: 0.515402\n",
      "[10000]\ttraining's l1: 0.132999\tvalid_1's l1: 0.514307\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.132999\tvalid_1's l1: 0.514307\n",
      "CV mean score: -0.6653, std: 0.0015.\n",
      "Training of type 7\n",
      "Fold 1 started at Sun Jun  9 16:47:37 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.123994\tvalid_1's l1: 0.225977\n",
      "[1000]\ttraining's l1: 0.0733401\tvalid_1's l1: 0.215576\n",
      "[1500]\ttraining's l1: 0.0468084\tvalid_1's l1: 0.211943\n",
      "[2000]\ttraining's l1: 0.0312781\tvalid_1's l1: 0.210149\n",
      "[2500]\ttraining's l1: 0.0213837\tvalid_1's l1: 0.209178\n",
      "[3000]\ttraining's l1: 0.0148414\tvalid_1's l1: 0.208638\n",
      "[3500]\ttraining's l1: 0.0105434\tvalid_1's l1: 0.20832\n",
      "[4000]\ttraining's l1: 0.00768349\tvalid_1's l1: 0.208135\n",
      "[4500]\ttraining's l1: 0.00576789\tvalid_1's l1: 0.208026\n",
      "[5000]\ttraining's l1: 0.00446796\tvalid_1's l1: 0.207953\n",
      "[5500]\ttraining's l1: 0.00356161\tvalid_1's l1: 0.207915\n",
      "[6000]\ttraining's l1: 0.0029247\tvalid_1's l1: 0.207879\n",
      "[6500]\ttraining's l1: 0.00245745\tvalid_1's l1: 0.207858\n",
      "[7000]\ttraining's l1: 0.00210955\tvalid_1's l1: 0.207845\n",
      "[7500]\ttraining's l1: 0.0018423\tvalid_1's l1: 0.20783\n",
      "[8000]\ttraining's l1: 0.00163958\tvalid_1's l1: 0.207822\n",
      "[8500]\ttraining's l1: 0.00148319\tvalid_1's l1: 0.207814\n",
      "[9000]\ttraining's l1: 0.00135866\tvalid_1's l1: 0.207806\n",
      "[9500]\ttraining's l1: 0.00126061\tvalid_1's l1: 0.2078\n",
      "[10000]\ttraining's l1: 0.00118232\tvalid_1's l1: 0.207797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00118232\tvalid_1's l1: 0.207797\n",
      "Fold 2 started at Sun Jun  9 16:50:40 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.123543\tvalid_1's l1: 0.22668\n",
      "[1000]\ttraining's l1: 0.0736621\tvalid_1's l1: 0.21667\n",
      "[1500]\ttraining's l1: 0.0475744\tvalid_1's l1: 0.212818\n",
      "[2000]\ttraining's l1: 0.0318036\tvalid_1's l1: 0.21107\n",
      "[2500]\ttraining's l1: 0.0215693\tvalid_1's l1: 0.210031\n",
      "[3000]\ttraining's l1: 0.0149947\tvalid_1's l1: 0.20948\n",
      "[3500]\ttraining's l1: 0.0106804\tvalid_1's l1: 0.209198\n",
      "[4000]\ttraining's l1: 0.0077988\tvalid_1's l1: 0.209029\n",
      "[4500]\ttraining's l1: 0.00585371\tvalid_1's l1: 0.20891\n",
      "[5000]\ttraining's l1: 0.00454043\tvalid_1's l1: 0.208833\n",
      "[5500]\ttraining's l1: 0.00362181\tvalid_1's l1: 0.208778\n",
      "[6000]\ttraining's l1: 0.00296997\tvalid_1's l1: 0.20874\n",
      "[6500]\ttraining's l1: 0.00249202\tvalid_1's l1: 0.208712\n",
      "[7000]\ttraining's l1: 0.00213462\tvalid_1's l1: 0.208692\n",
      "[7500]\ttraining's l1: 0.00186423\tvalid_1's l1: 0.208679\n",
      "[8000]\ttraining's l1: 0.00165523\tvalid_1's l1: 0.208667\n",
      "[8500]\ttraining's l1: 0.0014942\tvalid_1's l1: 0.208656\n",
      "[9000]\ttraining's l1: 0.00137182\tvalid_1's l1: 0.20865\n",
      "[9500]\ttraining's l1: 0.00127759\tvalid_1's l1: 0.208646\n",
      "[10000]\ttraining's l1: 0.00120099\tvalid_1's l1: 0.20864\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00120099\tvalid_1's l1: 0.20864\n",
      "Fold 3 started at Sun Jun  9 16:53:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.124598\tvalid_1's l1: 0.227032\n",
      "[1000]\ttraining's l1: 0.0748491\tvalid_1's l1: 0.217432\n",
      "[1500]\ttraining's l1: 0.0479364\tvalid_1's l1: 0.213805\n",
      "[2000]\ttraining's l1: 0.0316434\tvalid_1's l1: 0.211921\n",
      "[2500]\ttraining's l1: 0.0214457\tvalid_1's l1: 0.211054\n",
      "[3000]\ttraining's l1: 0.0149283\tvalid_1's l1: 0.210484\n",
      "[3500]\ttraining's l1: 0.010593\tvalid_1's l1: 0.210156\n",
      "[4000]\ttraining's l1: 0.00772038\tvalid_1's l1: 0.20994\n",
      "[4500]\ttraining's l1: 0.00581195\tvalid_1's l1: 0.209824\n",
      "[5000]\ttraining's l1: 0.00450439\tvalid_1's l1: 0.209734\n",
      "[5500]\ttraining's l1: 0.0035953\tvalid_1's l1: 0.209686\n",
      "[6000]\ttraining's l1: 0.00294812\tvalid_1's l1: 0.209654\n",
      "[6500]\ttraining's l1: 0.00248525\tvalid_1's l1: 0.209628\n",
      "[7000]\ttraining's l1: 0.00213857\tvalid_1's l1: 0.209606\n",
      "[7500]\ttraining's l1: 0.0018726\tvalid_1's l1: 0.209591\n",
      "[8000]\ttraining's l1: 0.0016568\tvalid_1's l1: 0.20958\n",
      "[8500]\ttraining's l1: 0.00148937\tvalid_1's l1: 0.209573\n",
      "[9000]\ttraining's l1: 0.00136357\tvalid_1's l1: 0.209565\n",
      "Early stopping, best iteration is:\n",
      "[9059]\ttraining's l1: 0.00134996\tvalid_1's l1: 0.209564\n",
      "Fold 4 started at Sun Jun  9 16:56:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.12463\tvalid_1's l1: 0.227571\n",
      "[1000]\ttraining's l1: 0.0744217\tvalid_1's l1: 0.217385\n",
      "[1500]\ttraining's l1: 0.0476088\tvalid_1's l1: 0.213662\n",
      "[2000]\ttraining's l1: 0.0317728\tvalid_1's l1: 0.211881\n",
      "[2500]\ttraining's l1: 0.0216504\tvalid_1's l1: 0.210919\n",
      "[3000]\ttraining's l1: 0.0150455\tvalid_1's l1: 0.210378\n",
      "[3500]\ttraining's l1: 0.0106937\tvalid_1's l1: 0.210058\n",
      "[4000]\ttraining's l1: 0.00778756\tvalid_1's l1: 0.209863\n",
      "[4500]\ttraining's l1: 0.0058482\tvalid_1's l1: 0.209752\n",
      "[5000]\ttraining's l1: 0.00452591\tvalid_1's l1: 0.209672\n",
      "[5500]\ttraining's l1: 0.00361374\tvalid_1's l1: 0.209627\n",
      "[6000]\ttraining's l1: 0.00296727\tvalid_1's l1: 0.209587\n",
      "[6500]\ttraining's l1: 0.00250317\tvalid_1's l1: 0.209559\n",
      "[7000]\ttraining's l1: 0.00216172\tvalid_1's l1: 0.20954\n",
      "[7500]\ttraining's l1: 0.00189865\tvalid_1's l1: 0.209526\n",
      "[8000]\ttraining's l1: 0.00168313\tvalid_1's l1: 0.209514\n",
      "[8500]\ttraining's l1: 0.00151098\tvalid_1's l1: 0.209506\n",
      "[9000]\ttraining's l1: 0.00137927\tvalid_1's l1: 0.209497\n",
      "[9500]\ttraining's l1: 0.00127937\tvalid_1's l1: 0.20949\n",
      "[10000]\ttraining's l1: 0.00119746\tvalid_1's l1: 0.209488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00119746\tvalid_1's l1: 0.209488\n",
      "Fold 5 started at Sun Jun  9 16:59:23 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.122723\tvalid_1's l1: 0.227353\n",
      "[1000]\ttraining's l1: 0.0730889\tvalid_1's l1: 0.216988\n",
      "[1500]\ttraining's l1: 0.0468\tvalid_1's l1: 0.213145\n",
      "[2000]\ttraining's l1: 0.0311629\tvalid_1's l1: 0.211299\n",
      "[2500]\ttraining's l1: 0.0211083\tvalid_1's l1: 0.210422\n",
      "[3000]\ttraining's l1: 0.0146975\tvalid_1's l1: 0.20992\n",
      "[3500]\ttraining's l1: 0.0104378\tvalid_1's l1: 0.209637\n",
      "[4000]\ttraining's l1: 0.00762643\tvalid_1's l1: 0.209463\n",
      "[4500]\ttraining's l1: 0.00574444\tvalid_1's l1: 0.209347\n",
      "[5000]\ttraining's l1: 0.00445972\tvalid_1's l1: 0.209272\n",
      "[5500]\ttraining's l1: 0.00357331\tvalid_1's l1: 0.209219\n",
      "[6000]\ttraining's l1: 0.00293556\tvalid_1's l1: 0.209177\n",
      "[6500]\ttraining's l1: 0.00246712\tvalid_1's l1: 0.20915\n",
      "[7000]\ttraining's l1: 0.00211818\tvalid_1's l1: 0.209134\n",
      "[7500]\ttraining's l1: 0.00185029\tvalid_1's l1: 0.20912\n",
      "[8000]\ttraining's l1: 0.00164493\tvalid_1's l1: 0.209109\n",
      "[8500]\ttraining's l1: 0.00148587\tvalid_1's l1: 0.2091\n",
      "[9000]\ttraining's l1: 0.00136316\tvalid_1's l1: 0.209096\n",
      "[9500]\ttraining's l1: 0.0012658\tvalid_1's l1: 0.209091\n",
      "[10000]\ttraining's l1: 0.00118891\tvalid_1's l1: 0.209087\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.00118891\tvalid_1's l1: 0.209087\n",
      "CV mean score: -1.5658, std: 0.0031.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147</td>\n",
       "      <td>11.224702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148</td>\n",
       "      <td>192.232365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149</td>\n",
       "      <td>7.763173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150</td>\n",
       "      <td>190.803494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151</td>\n",
       "      <td>9.660514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  scalar_coupling_constant\n",
       "0  4658147                 11.224702\n",
       "1  4658148                192.232365\n",
       "2  4658149                  7.763173\n",
       "3  4658150                190.803494\n",
       "4  4658151                  9.660514"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_short = pd.DataFrame({'ind': list(X.index), 'type': X['type'].values, 'oof': [0] * len(X), 'target': y.values})\n",
    "X_short_test = pd.DataFrame({'ind': list(X_test.index), 'type': X_test['type'].values, 'prediction': [0] * len(X_test)})\n",
    "for t in X['type'].unique():\n",
    "    print(f'Training of type {t}')\n",
    "    X_t = X.loc[X['type'] == t]\n",
    "    X_test_t = X_test.loc[X_test['type'] == t]\n",
    "    y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "    \n",
    "    result_dict_lgb3 = train_model_regression(X=X_t, \n",
    "                                              X_test=X_test_t, \n",
    "                                              y=y_t, \n",
    "                                              params=params, \n",
    "                                              folds=folds, \n",
    "                                              model_type='lgb', \n",
    "                                              eval_metric='group_mae', \n",
    "                                              plot_feature_importance=False,\n",
    "                                              verbose=500, \n",
    "                                              early_stopping_rounds=200, \n",
    "                                              n_estimators=10000)\n",
    "    X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb3['oof']\n",
    "    X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb3['prediction']\n",
    "    \n",
    "sub['scalar_coupling_constant'] = X_short_test['prediction']\n",
    "sub.to_csv('submission_t.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 66356\r\n",
      "-rw-rw-r-- 1 kenichi.matsui    11215 Jun  6 01:31 feature_eng_001.ipynb\r\n",
      "-rw-rw-r-- 1 kenichi.matsui   273097 Jun  7 12:03 predict_v001_005.ipynb\r\n",
      "-rw-rw-r-- 1 kenichi.matsui 67136431 Jun  9 17:02 submission_t.csv\r\n",
      "-rw-rw-r-- 1 kenichi.matsui   387558 Jun  6 01:31 train_v001_001.ipynb\r\n",
      "-rw-r--r-- 1 kenichi.matsui   133413 Jun  9 17:01 Using meta-features to improve model.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with oof feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'num_leaves': 128,\n",
    "#           'min_child_samples': 79,\n",
    "#           'objective': 'regression',\n",
    "#           'max_depth': 9,\n",
    "#           'learning_rate': 0.2,\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"subsample_freq\": 1,\n",
    "#           \"subsample\": 0.9,\n",
    "#           \"bagging_seed\": 11,\n",
    "#           \"metric\": 'mae',\n",
    "#           \"verbosity\": -1,\n",
    "#           'reg_alpha': 0.1,\n",
    "#           'reg_lambda': 0.3,\n",
    "#           'colsample_bytree': 1.0\n",
    "#          }\n",
    "# result_dict_lgb2 = train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "#                                                       verbose=500, early_stopping_rounds=200, n_estimators=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'num_leaves': 128,\n",
    "#           'min_child_samples': 79,\n",
    "#           'objective': 'regression',\n",
    "#           'max_depth': 9,\n",
    "#           'learning_rate': 0.2,\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"subsample_freq\": 1,\n",
    "#           \"subsample\": 0.9,\n",
    "#           \"bagging_seed\": 11,\n",
    "#           \"metric\": 'mae',\n",
    "#           \"verbosity\": -1,\n",
    "#           'reg_alpha': 0.1,\n",
    "#           'reg_lambda': 0.3,\n",
    "#           'colsample_bytree': 1.0\n",
    "#          }\n",
    "# result_dict_lgb2 = train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "#                                                       verbose=500, early_stopping_rounds=200, n_estimators=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub['scalar_coupling_constant'] = result_dict_lgb2['prediction']\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot oof predictions vs target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame(y)\n",
    "plot_data.index.name = 'id'\n",
    "plot_data['yhat'] = result_dict_lgb3['oof']\n",
    "plot_data['type'] = lbl.inverse_transform(X['type'])\n",
    "\n",
    "def plot_oof_preds(ctype, llim, ulim):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        sns.scatterplot(x='scalar_coupling_constant',y='yhat',\n",
    "                        data=plot_data.loc[plot_data['type']==ctype,\n",
    "                        ['scalar_coupling_constant', 'yhat']]);\n",
    "        plt.xlim((llim, ulim))\n",
    "        plt.ylim((llim, ulim))\n",
    "        plt.plot([llim, ulim], [llim, ulim])\n",
    "        plt.xlabel('scalar_coupling_constant')\n",
    "        plt.ylabel('predicted')\n",
    "        plt.title(f'{ctype}', fontsize=18)\n",
    "        plt.show()\n",
    "\n",
    "plot_oof_preds('1JHC', 0, 250)\n",
    "plot_oof_preds('1JHN', 0, 100)\n",
    "plot_oof_preds('2JHC', -50, 50)\n",
    "plot_oof_preds('2JHH', -50, 50)\n",
    "plot_oof_preds('2JHN', -25, 25)\n",
    "plot_oof_preds('3JHC', -25, 100)\n",
    "plot_oof_preds('3JHH', -20, 20)\n",
    "plot_oof_preds('3JHN', -15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
